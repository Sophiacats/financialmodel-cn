import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
import re
import requests
import time
warnings.filterwarnings('ignore')

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ğŸ“° è´¢ç»æ–°é—»æ™ºèƒ½åˆ†æç³»ç»Ÿ",
    page_icon="ğŸ“°",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ– session state
if 'selected_ticker' not in st.session_state:
    st.session_state.selected_ticker = None
if 'news_data' not in st.session_state:
    st.session_state.news_data = None

st.title("ğŸ“° è´¢ç»æ–°é—»æ™ºèƒ½åˆ†æç³»ç»Ÿ")
st.markdown("**å®æ—¶è´¢ç»æ–°é—» + æ™ºèƒ½ä¸­æ–‡ç¿»è¯‘ + æƒ…ç»ªåˆ†æ + æŠ•èµ„å»ºè®®**")
st.markdown("---")

# ==================== ç¿»è¯‘å’Œåˆ†æå‡½æ•° ====================

def comprehensive_translate(text):
    """ç»¼åˆç¿»è¯‘ï¼šå¥å‹+è¯æ±‡ç¿»è¯‘"""
    if not text:
        return text
    
    # å…ˆè¿›è¡Œå¥å‹ç¿»è¯‘
    sentence_patterns = {
        # æ–°é—»å¼€å¤´å¸¸è§å¥å‹
        r'(\w+)\s+announced\s+that': r'\1å®£å¸ƒ',
        r'(\w+)\s+reported\s+that': r'\1æŠ¥å‘Šç§°',
        r'(\w+)\s+said\s+that': r'\1è¡¨ç¤º',
        r'(\w+)\s+revealed\s+that': r'\1é€éœ²',
        r'(\w+)\s+disclosed\s+that': r'\1æŠ«éœ²',
        r'(\w+)\s+confirmed\s+that': r'\1ç¡®è®¤',
        r'according\s+to\s+(\w+)': r'æ®\1',
        
        # è´¢æŠ¥ç›¸å…³å¥å‹
        r'(\w+)\s+posted\s+(\w+)\s+earnings': r'\1å…¬å¸ƒäº†\2è´¢æŠ¥',
        r'(\w+)\s+beat\s+earnings\s+expectations': r'\1è´¢æŠ¥è¶…é¢„æœŸ',
        r'(\w+)\s+missed\s+earnings\s+expectations': r'\1è´¢æŠ¥ä¸åŠé¢„æœŸ',
        r'(\w+)\s+reported\s+revenue\s+of\s+\$([0-9.]+)\s+billion': r'\1æŠ¥å‘Šè¥æ”¶\2åäº¿ç¾å…ƒ',
        r'(\w+)\s+reported\s+revenue\s+of\s+\$([0-9.]+)\s+million': r'\1æŠ¥å‘Šè¥æ”¶\2ç™¾ä¸‡ç¾å…ƒ',
        r'revenue\s+increased\s+by\s+([0-9.]+)%': r'è¥æ”¶å¢é•¿\1%',
        r'revenue\s+decreased\s+by\s+([0-9.]+)%': r'è¥æ”¶ä¸‹é™\1%',
        
        # è‚¡ä»·ç›¸å…³å¥å‹
        r'(\w+)\s+shares\s+rose\s+([0-9.]+)%': r'\1è‚¡ä»·ä¸Šæ¶¨\2%',
        r'(\w+)\s+shares\s+fell\s+([0-9.]+)%': r'\1è‚¡ä»·ä¸‹è·Œ\2%',
        r'(\w+)\s+shares\s+gained\s+([0-9.]+)%': r'\1è‚¡ä»·ä¸Šæ¶¨\2%',
        r'(\w+)\s+shares\s+dropped\s+([0-9.]+)%': r'\1è‚¡ä»·ä¸‹è·Œ\2%',
        r'shares\s+closed\s+at\s+\$([0-9.]+)': r'è‚¡ä»·æ”¶äº\1ç¾å…ƒ',
        
        # å…¬å¸è¡ŒåŠ¨å¥å‹
        r'(\w+)\s+will\s+acquire\s+(\w+)': r'\1å°†æ”¶è´­\2',
        r'(\w+)\s+acquired\s+(\w+)': r'\1æ”¶è´­äº†\2',
        r'(\w+)\s+launched\s+a?\s*new\s+(\w+)': r'\1æ¨å‡ºæ–°\2',
        r'(\w+)\s+introduced\s+(\w+)': r'\1æ¨å‡º\2',
        r'(\w+)\s+unveiled\s+(\w+)': r'\1å‘å¸ƒ\2',
        r'(\w+)\s+plans\s+to\s+(\w+)': r'\1è®¡åˆ’\2',
        r'(\w+)\s+expects\s+to\s+(\w+)': r'\1é¢„è®¡å°†\2',
        r'(\w+)\s+is\s+expected\s+to\s+(\w+)': r'\1é¢„è®¡å°†\2',
        
        # æ—¶é—´è¡¨è¾¾
        r'this\s+quarter': 'æœ¬å­£åº¦',
        r'last\s+quarter': 'ä¸Šå­£åº¦',
        r'this\s+year': 'ä»Šå¹´',
        r'last\s+year': 'å»å¹´',
        r'compared\s+to\s+last\s+year': 'ä¸å»å¹´ç›¸æ¯”',
        r'year-over-year': 'åŒæ¯”',
        
        # å¸¸è§çŸ­è¯­
        r'beat\s+expectations': 'è¶…é¢„æœŸ',
        r'missed\s+expectations': 'ä¸åŠé¢„æœŸ',
        r'better\s+than\s+expected': 'å¥½äºé¢„æœŸ',
        r'record\s+high': 'å†å²æ–°é«˜',
        r'all-time\s+high': 'å†å²æœ€é«˜',
        
        # æ•°å­—è¡¨è¾¾
        r'\$([0-9.]+)\s+billion': r'\1åäº¿ç¾å…ƒ',
        r'\$([0-9.]+)\s+million': r'\1ç™¾ä¸‡ç¾å…ƒ',
        r'([0-9.]+)\s+billion': r'\1åäº¿',
        r'([0-9.]+)\s+million': r'\1ç™¾ä¸‡',
        
        # è¡Œä¸šæœ¯è¯­
        r'artificial\s+intelligence': 'äººå·¥æ™ºèƒ½',
        r'machine\s+learning': 'æœºå™¨å­¦ä¹ ',
        r'cloud\s+computing': 'äº‘è®¡ç®—',
        r'electric\s+vehicles?': 'ç”µåŠ¨æ±½è½¦',
        r'renewable\s+energy': 'å¯å†ç”Ÿèƒ½æº',
    }
    
    result = text
    
    # åº”ç”¨å¥å‹ç¿»è¯‘
    for pattern, replacement in sentence_patterns.items():
        result = re.sub(pattern, replacement, result, flags=re.IGNORECASE)
    
    # ç„¶ååº”ç”¨åŸºç¡€è¯æ±‡ç¿»è¯‘
    result = basic_financial_translate(result)
    
    return result

def basic_financial_translate(text):
    """åŸºç¡€è´¢ç»æœ¯è¯­ç¿»è¯‘"""
    if not text:
        return text
    
    financial_dict = {
        # å…¬å¸åç§°
        'Apple Inc': 'è‹¹æœå…¬å¸',
        'Apple': 'è‹¹æœå…¬å¸',
        'Tesla Inc': 'ç‰¹æ–¯æ‹‰å…¬å¸', 
        'Tesla': 'ç‰¹æ–¯æ‹‰å…¬å¸',
        'Microsoft Corporation': 'å¾®è½¯å…¬å¸',
        'Microsoft': 'å¾®è½¯å…¬å¸',
        'Amazon.com Inc': 'äºšé©¬é€Šå…¬å¸',
        'Amazon': 'äºšé©¬é€Šå…¬å¸',
        'Google': 'è°·æ­Œ',
        'Meta': 'Metaå…¬å¸',
        'NVIDIA': 'è‹±ä¼Ÿè¾¾',
        'Netflix': 'å¥ˆé£',
        'Facebook': 'è„¸ä¹¦',
        
        # è‚¡ç¥¨ä»£ç 
        'AAPL': 'è‹¹æœ(AAPL)',
        'TSLA': 'ç‰¹æ–¯æ‹‰(TSLA)',
        'MSFT': 'å¾®è½¯(MSFT)',
        'AMZN': 'äºšé©¬é€Š(AMZN)',
        'GOOGL': 'è°·æ­Œ(GOOGL)',
        'META': 'Meta(META)',
        'NVDA': 'è‹±ä¼Ÿè¾¾(NVDA)',
        'NFLX': 'å¥ˆé£(NFLX)',
        
        # è´¢ç»æœ¯è¯­
        'earnings report': 'è´¢æŠ¥',
        'quarterly earnings': 'å­£åº¦è´¢æŠ¥',
        'revenue': 'è¥æ”¶',
        'profit': 'åˆ©æ¶¦',
        'loss': 'äºæŸ',
        'dividend': 'åˆ†çº¢',
        'stock price': 'è‚¡ä»·',
        'market cap': 'å¸‚å€¼',
        'investment': 'æŠ•èµ„',
        'investor': 'æŠ•èµ„è€…',
        'shareholder': 'è‚¡ä¸œ',
        'CEO': 'é¦–å¸­æ‰§è¡Œå®˜',
        'CFO': 'é¦–å¸­è´¢åŠ¡å®˜',
        
        # åŸºç¡€è¯æ±‡
        'technology': 'ç§‘æŠ€',
        'artificial intelligence': 'äººå·¥æ™ºèƒ½',
        'AI': 'äººå·¥æ™ºèƒ½',
        'semiconductor': 'åŠå¯¼ä½“',
        'electric vehicle': 'ç”µåŠ¨æ±½è½¦',
        'cloud computing': 'äº‘è®¡ç®—',
        'e-commerce': 'ç”µå­å•†åŠ¡',
        'streaming': 'æµåª’ä½“',
        
        # æ•°å€¼è¡¨è¾¾
        'billion': 'åäº¿',
        'million': 'ç™¾ä¸‡',
        'percent': 'ç™¾åˆ†æ¯”',
        
        # å¸‚åœºåŠ¨ä½œ
        'announced': 'å®£å¸ƒ',
        'reported': 'æŠ¥å‘Š',
        'released': 'å‘å¸ƒ',
        'launched': 'æ¨å‡º',
        'acquired': 'æ”¶è´­',
        'merged': 'åˆå¹¶',
        
        # å…¶ä»–å¸¸ç”¨è¯
        'growth': 'å¢é•¿',
        'decline': 'ä¸‹é™',
        'increase': 'å¢åŠ ',
        'decrease': 'å‡å°‘',
        'performance': 'è¡¨ç°',
        'results': 'ç»“æœ',
        'forecast': 'é¢„æµ‹',
        'outlook': 'å±•æœ›',
        'guidance': 'æŒ‡å¯¼',
        'target': 'ç›®æ ‡',
        
        # å®Œæ•´å¥å¼
        'said in a statement': 'åœ¨å£°æ˜ä¸­è¡¨ç¤º',
        'according to': 'æ®',
        'is expected to': 'é¢„è®¡å°†',
        'announced today': 'ä»Šæ—¥å®£å¸ƒ',
        'shares rose': 'è‚¡ä»·ä¸Šæ¶¨',
        'shares fell': 'è‚¡ä»·ä¸‹è·Œ',
        'revenue growth': 'è¥æ”¶å¢é•¿',
        'net income': 'å‡€åˆ©æ¶¦',
        'cash flow': 'ç°é‡‘æµ',
        'market value': 'å¸‚å€¼',
        'stock market': 'è‚¡å¸‚',
        'board of directors': 'è‘£äº‹ä¼š',
        'supply chain': 'ä¾›åº”é“¾',
        'research and development': 'ç ”å‘',
        'initial public offering': 'é¦–æ¬¡å…¬å¼€å‹Ÿè‚¡',
        'mergers and acquisitions': 'å¹¶è´­',
    }
    
    result = text
    for en, zh in financial_dict.items():
        pattern = r'\b' + re.escape(en) + r'\b'
        result = re.sub(pattern, zh, result, flags=re.IGNORECASE)
    
    return result

def translate_with_google_alternative(text):
    """ä½¿ç”¨Googleç¿»è¯‘çš„æ›¿ä»£æ¥å£ï¼ˆå¿«é€Ÿç‰ˆæœ¬ï¼‰"""
    try:
        url = "https://translate.google.cn/translate_a/single"
        params = {
            'client': 'gtx',
            'sl': 'en',
            'tl': 'zh',
            'dt': 't',
            'q': text[:500]
        }
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = requests.get(url, params=params, headers=headers, timeout=3)
        if response.status_code == 200:
            result = response.json()
            if result and len(result) > 0 and result[0]:
                translated_parts = []
                for item in result[0]:
                    if item and len(item) > 0 and item[0]:
                        translated_parts.append(item[0])
                if translated_parts:
                    return ''.join(translated_parts)
    except:
        pass
    return None

def smart_translate(text):
    """æ™ºèƒ½ç¿»è¯‘ï¼šä¼˜å…ˆä½¿ç”¨ç»¼åˆç¿»è¯‘ï¼ŒçŸ­æ–‡æœ¬å°è¯•åœ¨çº¿ç¿»è¯‘"""
    if not text or len(text.strip()) < 3:
        return text
    
    # ä½¿ç”¨ç»¼åˆç¿»è¯‘
    translated = comprehensive_translate(text)
    
    # å¦‚æœç¿»è¯‘æ•ˆæœè¿˜æ˜¯ä¸å¤Ÿå¥½ï¼Œå°è¯•åœ¨çº¿ç¿»è¯‘ï¼ˆä»…é™çŸ­æ–‡æœ¬ï¼‰
    if len(text) < 200 and translated == text:
        try:
            online_result = translate_with_google_alternative(text)
            if online_result and len(online_result.strip()) > 5:
                return online_result
        except:
            pass
    
    return translated

def extract_keywords_from_text(text):
    """ä»æ–‡æœ¬ä¸­æå–è´¢ç»å…³é”®è¯"""
    if not text:
        return []
    
    text_lower = text.lower()
    
    keyword_categories = {
        "åˆ©ç‡": ["rate", "interest", "fed", "federal reserve", "åˆ©ç‡", "é™æ¯", "åŠ æ¯"],
        "ç§‘æŠ€": ["tech", "technology", "ai", "artificial intelligence", "chip", "semiconductor", "ç§‘æŠ€", "äººå·¥æ™ºèƒ½", "èŠ¯ç‰‡"],
        "é‡‘è": ["bank", "financial", "finance", "credit", "loan", "é“¶è¡Œ", "é‡‘è", "ä¿¡è´·"],
        "èƒ½æº": ["energy", "oil", "gas", "petroleum", "renewable", "èƒ½æº", "çŸ³æ²¹", "å¤©ç„¶æ°”"],
        "ä¸Šæ¶¨": ["up", "rise", "gain", "increase", "rally", "surge", "ä¸Šæ¶¨", "å¢é•¿", "ä¸Šå‡"],
        "ä¸‹è·Œ": ["down", "fall", "drop", "decline", "crash", "ä¸‹è·Œ", "ä¸‹é™", "æš´è·Œ"],
        "é€šèƒ€": ["inflation", "cpi", "consumer price", "é€šèƒ€", "ç‰©ä»·"],
        "æ”¿ç­–": ["policy", "regulation", "government", "æ”¿ç­–", "ç›‘ç®¡", "æ”¿åºœ"],
        "ç»æµå¢é•¿": ["growth", "gdp", "economic", "economy", "ç»æµ", "å¢é•¿"],
        "å¸‚åœº": ["market", "stock", "trading", "investor", "å¸‚åœº", "è‚¡ç¥¨", "æŠ•èµ„"]
    }
    
    found_keywords = []
    for category, words in keyword_categories.items():
        for word in words:
            if word in text_lower:
                found_keywords.append(category)
                break
    
    return found_keywords[:5]

def analyze_sentiment_from_keywords(keywords):
    """æ ¹æ®å…³é”®è¯åˆ†ææƒ…ç»ª"""
    bullish_words = ["ä¸Šæ¶¨", "å¢é•¿", "åˆ©ç‡", "ç§‘æŠ€", "ç»æµå¢é•¿"]
    bearish_words = ["ä¸‹è·Œ", "é€šèƒ€", "æ”¿ç­–"]
    
    bullish_count = sum(1 for kw in keywords if kw in bullish_words)
    bearish_count = sum(1 for kw in keywords if kw in bearish_words)
    
    if bullish_count > bearish_count:
        return "åˆ©å¥½"
    elif bearish_count > bullish_count:
        return "åˆ©ç©º"
    else:
        return "ä¸­æ€§"

def get_market_impact_advice(sentiment):
    """æ ¹æ®æƒ…ç»ªç»™å‡ºå¸‚åœºå½±å“å»ºè®®"""
    if sentiment == "åˆ©å¥½":
        return {
            "icon": "ğŸ“ˆ",
            "advice": "ç§¯æå› ç´ ï¼Œå¯å…³æ³¨ç›¸å…³æ¿å—æœºä¼š",
            "action": "å»ºè®®å…³æ³¨ç›¸å…³æ¦‚å¿µè‚¡ï¼Œé€‚å½“å¢åŠ ä»“ä½",
            "color": "green"
        }
    elif sentiment == "åˆ©ç©º":
        return {
            "icon": "ğŸ“‰", 
            "advice": "é£é™©å› ç´ ï¼Œå»ºè®®è°¨æ…æ“ä½œ",
            "action": "é™ä½é£é™©æ•å£ï¼Œå…³æ³¨é˜²å¾¡æ€§æ¿å—",
            "color": "red"
        }
    else:
        return {
            "icon": "ğŸ“Š",
            "advice": "ä¸­æ€§å½±å“ï¼Œç»´æŒç°æœ‰ç­–ç•¥",
            "action": "å¯†åˆ‡å…³æ³¨åç»­å‘å±•ï¼Œä¿æŒçµæ´»æ“ä½œ",
            "color": "gray"
        }

# ==================== æ–°é—»è·å–å‡½æ•° ====================

@st.cache_data(ttl=1800)  # ç¼“å­˜30åˆ†é’Ÿ
def fetch_financial_news(target_ticker=None):
    """è·å–çœŸå®è´¢ç»æ–°é—»"""
    try:
        current_time = datetime.now()
        news_data = []
        
        # è·å–ç›®æ ‡è‚¡ç¥¨æ–°é—»
        if target_ticker:
            try:
                ticker_obj = yf.Ticker(target_ticker)
                news = ticker_obj.news
                
                if news and len(news) > 0:
                    for i, article in enumerate(news[:8]):
                        try:
                            # å¤„ç†ä¸åŒçš„æ–°é—»æ•°æ®ç»“æ„
                            if isinstance(article, dict):
                                content = article
                            else:
                                content = article.get('content', article)
                            
                            title = content.get('title', '') or content.get('headline', '')
                            summary = content.get('summary', '') or content.get('description', '') or content.get('snippet', '')
                            
                            # è·å–é“¾æ¥
                            link = ''
                            if 'clickThroughUrl' in content and content['clickThroughUrl']:
                                link = content['clickThroughUrl'].get('url', '')
                            elif 'canonicalUrl' in content and content['canonicalUrl']:
                                link = content['canonicalUrl'].get('url', '')
                            else:
                                link = content.get('link', '') or content.get('url', '')
                            
                            # è·å–å‘å¸ƒè€…
                            publisher = 'Unknown'
                            if 'provider' in content and content['provider']:
                                publisher = content['provider'].get('displayName', 'Unknown')
                            else:
                                publisher = content.get('publisher', '') or content.get('source', 'Unknown')
                            
                            # è·å–æ—¶é—´
                            published_time = current_time - timedelta(hours=i+1)
                            if 'pubDate' in content:
                                pub_date_str = content['pubDate']
                            elif 'displayTime' in content:
                                pub_date_str = content['displayTime']
                            else:
                                pub_date_str = ''
                            
                            if pub_date_str:
                                try:
                                    if 'T' in pub_date_str and 'Z' in pub_date_str:
                                        published_time = datetime.fromisoformat(pub_date_str.replace('Z', '+00:00')).replace(tzinfo=None)
                                    elif isinstance(pub_date_str, str) and len(pub_date_str) > 10:
                                        published_time = datetime.strptime(pub_date_str[:19], '%Y-%m-%d %H:%M:%S') if ':' in pub_date_str else published_time
                                except:
                                    pass
                            
                            # å¤„ç†providerPublishTime
                            if 'providerPublishTime' in content and content['providerPublishTime']:
                                try:
                                    published_time = datetime.fromtimestamp(content['providerPublishTime'])
                                except:
                                    pass
                            
                            if title and len(title.strip()) > 5:
                                # ç¿»è¯‘æ ‡é¢˜å’Œæ‘˜è¦
                                try:
                                    translated_title = smart_translate(title)
                                    if summary and len(summary.strip()) > 10:
                                        if len(summary) > 400:
                                            summary = summary[:400] + "..."
                                        translated_summary = smart_translate(summary)
                                    else:
                                        translated_summary = 'æš‚æ— æ‘˜è¦'
                                except Exception as e:
                                    translated_title = basic_financial_translate(title)
                                    translated_summary = basic_financial_translate(summary) if summary else 'æš‚æ— æ‘˜è¦'
                                
                                # æå–å…³é”®è¯å’Œåˆ†ææƒ…ç»ª
                                title_summary = title + ' ' + (summary or '')
                                keywords = extract_keywords_from_text(title_summary)
                                sentiment = analyze_sentiment_from_keywords(keywords)
                                
                                news_item = {
                                    "title": translated_title,
                                    "summary": translated_summary[:300] + '...' if len(translated_summary) > 300 else translated_summary,
                                    "published": published_time,
                                    "url": link or '',
                                    "source": publisher,
                                    "category": "company_specific",
                                    "keywords": keywords,
                                    "sentiment": sentiment,
                                    "is_real": True,
                                    "ticker": target_ticker
                                }
                                news_data.append(news_item)
                        except Exception as e:
                            continue
            except Exception as e:
                st.warning(f"è·å– {target_ticker} æ–°é—»æ—¶å‡ºé”™: {str(e)}")
        
        # è·å–å¸‚åœºæ•´ä½“æ–°é—»
        try:
            market_indices = ["^GSPC", "^IXIC", "^DJI"]
            for index_symbol in market_indices:
                try:
                    index_ticker = yf.Ticker(index_symbol)
                    index_news = index_ticker.news
                    
                    if index_news and len(index_news) > 0:
                        for j, article in enumerate(index_news[:3]):
                            try:
                                if isinstance(article, dict):
                                    content = article
                                else:
                                    content = article.get('content', article)
                                
                                title = content.get('title', '') or content.get('headline', '')
                                summary = content.get('summary', '') or content.get('description', '') or content.get('snippet', '')
                                
                                # è·å–é“¾æ¥
                                link = ''
                                if 'clickThroughUrl' in content and content['clickThroughUrl']:
                                    link = content['clickThroughUrl'].get('url', '')
                                elif 'canonicalUrl' in content and content['canonicalUrl']:
                                    link = content['canonicalUrl'].get('url', '')
                                else:
                                    link = content.get('link', '') or content.get('url', '')
                                
                                # è·å–å‘å¸ƒè€…
                                publisher = 'Market News'
                                if 'provider' in content and content['provider']:
                                    publisher = content['provider'].get('displayName', 'Market News')
                                else:
                                    publisher = content.get('publisher', '') or content.get('source', 'Market News')
                                
                                # è·å–æ—¶é—´
                                published_time = current_time - timedelta(hours=len(news_data)+1)
                                if 'providerPublishTime' in content and content['providerPublishTime']:
                                    try:
                                        published_time = datetime.fromtimestamp(content['providerPublishTime'])
                                    except:
                                        pass
                                
                                if title and len(title.strip()) > 5:
                                    # é¿å…é‡å¤æ–°é—»
                                    if not any(existing['title'] == title for existing in news_data):
                                        try:
                                            translated_title = smart_translate(title)
                                            if summary and len(summary.strip()) > 10:
                                                if len(summary) > 400:
                                                    summary = summary[:400] + "..."
                                                translated_summary = smart_translate(summary)
                                            else:
                                                translated_summary = 'æš‚æ— æ‘˜è¦'
                                        except:
                                            translated_title = basic_financial_translate(title)
                                            translated_summary = basic_financial_translate(summary) if summary else 'æš‚æ— æ‘˜è¦'
                                        
                                        title_summary = title + ' ' + (summary or '')
                                        keywords = extract_keywords_from_text(title_summary)
                                        sentiment = analyze_sentiment_from_keywords(keywords)
                                        
                                        news_item = {
                                            "title": translated_title,
                                            "summary": translated_summary[:300] + '...' if len(translated_summary) > 300 else translated_summary,
                                            "published": published_time,
                                            "url": link or '',
                                            "source": publisher,
                                            "category": "market_wide",
                                            "keywords": keywords,
                                            "sentiment": sentiment,
                                            "is_real": True,
                                            "ticker": index_symbol
                                        }
                                        news_data.append(news_item)
                            except Exception as e:
                                continue
                except Exception as e:
                    continue
        except Exception as e:
            pass
        
        # æŒ‰æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
        news_data.sort(key=lambda x: x.get('published', datetime.now()), reverse=True)
        
        # å¦‚æœä»ç„¶æ²¡æœ‰æ–°é—»ï¼Œæä¾›ç³»ç»Ÿæç¤º
        if len(news_data) == 0:
            return [{
                "title": "æ–°é—»è·å–æœåŠ¡æš‚æ—¶ä¸å¯ç”¨",
                "summary": "ç”±äºæŠ€æœ¯åŸå› ï¼Œæš‚æ—¶æ— æ³•è·å–å®æ—¶è´¢ç»æ–°é—»ã€‚è¯·ç›´æ¥è®¿é—®Yahoo Financeã€Bloombergç­‰è´¢ç»ç½‘ç«™è·å–æœ€æ–°å¸‚åœºä¿¡æ¯ã€‚",
                "published": current_time,
                "url": "https://finance.yahoo.com",
                "source": "ç³»ç»Ÿæç¤º",
                "category": "system_info",
                "keywords": ["ç³»ç»Ÿ", "æç¤º"],
                "sentiment": "ä¸­æ€§",
                "is_real": False,
                "ticker": ""
            }]
        
        return news_data
        
    except Exception as e:
        st.error(f"æ–°é—»è·å–å‡ºé”™: {str(e)}")
        return [{
            "title": "æ–°é—»è·å–æœåŠ¡æš‚æ—¶ä¸å¯ç”¨",
            "summary": "ç”±äºæŠ€æœ¯åŸå› ï¼Œæš‚æ—¶æ— æ³•è·å–å®æ—¶è´¢ç»æ–°é—»ã€‚è¯·ç›´æ¥è®¿é—®è´¢ç»ç½‘ç«™è·å–æœ€æ–°å¸‚åœºä¿¡æ¯ã€‚",
            "published": datetime.now(),
            "url": "",
            "source": "ç³»ç»Ÿ",
            "category": "system_info",
            "keywords": ["ç³»ç»Ÿ"],
            "sentiment": "ä¸­æ€§",
            "is_real": False,
            "ticker": ""
        }]

# ==================== ä¾§è¾¹æ  ====================
with st.sidebar:
    st.header("ğŸ“° æ–°é—»åˆ†æè®¾ç½®")
    
    # è‚¡ç¥¨é€‰æ‹©
    popular_stocks = {
        "å¸‚åœºç»¼åˆæ–°é—»": "",
        "Apple (AAPL)": "AAPL",
        "Microsoft (MSFT)": "MSFT", 
        "Tesla (TSLA)": "TSLA",
        "Amazon (AMZN)": "AMZN",
        "Google (GOOGL)": "GOOGL",
        "Meta (META)": "META",
        "NVIDIA (NVDA)": "NVDA",
        "Netflix (NFLX)": "NFLX"
    }
    
    selected_stock = st.selectbox(
        "é€‰æ‹©å…³æ³¨è‚¡ç¥¨:",
        options=list(popular_stocks.keys()),
        index=0
    )
    
    # æˆ–è€…æ‰‹åŠ¨è¾“å…¥è‚¡ç¥¨ä»£ç 
    manual_ticker = st.text_input(
        "æˆ–è¾“å…¥è‚¡ç¥¨ä»£ç :",
        placeholder="ä¾‹å¦‚: AAPL, TSLA, MSFT"
    ).upper()
    
    # ç¡®å®šè¦åˆ†æçš„è‚¡ç¥¨
    if manual_ticker:
        ticker = manual_ticker
    else:
        ticker = popular_stocks[selected_stock]
    
    # æ–°é—»ç­›é€‰é€‰é¡¹
    st.markdown("---")
    st.subheader("ğŸ” æ–°é—»ç­›é€‰")
    
    sentiment_filter = st.selectbox(
        "æƒ…ç»ªç­›é€‰:",
        ["å…¨éƒ¨", "åˆ©å¥½", "åˆ©ç©º", "ä¸­æ€§"]
    )
    
    time_filter = st.selectbox(
        "æ—¶é—´ç­›é€‰:",
        ["å…¨éƒ¨", "ä»Šæ—¥", "è¿‘3å¤©", "ä¸€å‘¨å†…"]
    )
    
    keyword_filter = st.multiselect(
        "å…³é”®è¯ç­›é€‰:",
        ["ç§‘æŠ€", "é‡‘è", "èƒ½æº", "ä¸Šæ¶¨", "ä¸‹è·Œ", "åˆ©ç‡", "é€šèƒ€", "æ”¿ç­–", "ç»æµå¢é•¿", "å¸‚åœº"]
    )
    
    # è·å–æ–°é—»æŒ‰é’®
    if st.button("ğŸ” è·å–æœ€æ–°æ–°é—»", type="primary"):
        st.session_state.selected_ticker = ticker
        with st.spinner("æ­£åœ¨è·å–æœ€æ–°è´¢ç»æ–°é—»..."):
            news_data = fetch_financial_news(ticker if ticker else None)
            st.session_state.news_data = news_data
    
    # æ¸…é™¤ç¼“å­˜æŒ‰é’®
    if st.button("ğŸ”„ åˆ·æ–°æ–°é—»"):
        fetch_financial_news.clear()
        st.session_state.news_data = None
        st.rerun()
    
    st.markdown("---")
    st.markdown("### ğŸ“Š ä½¿ç”¨è¯´æ˜")
    st.markdown("""
    **åŠŸèƒ½ç‰¹è‰²:**
    - ğŸ”„ å®æ—¶è·å–Yahoo Financeæ–°é—»
    - ğŸŒ æ™ºèƒ½ä¸­æ–‡ç¿»è¯‘
    - ğŸ¯ å…³é”®è¯æå–
    - ğŸ“ˆ æƒ…ç»ªåˆ†æ
    - ğŸ’¡ æŠ•èµ„å»ºè®®
    
    **ä½¿ç”¨æ­¥éª¤:**
    1. é€‰æ‹©å…³æ³¨è‚¡ç¥¨æˆ–è¾“å…¥ä»£ç 
    2. è®¾ç½®ç­›é€‰æ¡ä»¶
    3. ç‚¹å‡»è·å–æœ€æ–°æ–°é—»
    4. æŸ¥çœ‹åˆ†æç»“æœ
    """)

# ==================== ä¸»ç•Œé¢ ====================
if st.session_state.news_data is not None:
    news_data = st.session_state.news_data
    
    # åº”ç”¨ç­›é€‰æ¡ä»¶
    filtered_news = news_data.copy()
    
    # æƒ…ç»ªç­›é€‰
    if sentiment_filter != "å…¨éƒ¨":
        filtered_news = [news for news in filtered_news if news['sentiment'] == sentiment_filter]
    
    # æ—¶é—´ç­›é€‰
    if time_filter != "å…¨éƒ¨":
        now = datetime.now()
        if time_filter == "ä»Šæ—¥":
            filtered_news = [news for news in filtered_news if news['published'].date() == now.date()]
        elif time_filter == "è¿‘3å¤©":
            filtered_news = [news for news in filtered_news if (now - news['published']).days <= 3]
        elif time_filter == "ä¸€å‘¨å†…":
            filtered_news = [news for news in filtered_news if (now - news['published']).days <= 7]
    
    # å…³é”®è¯ç­›é€‰
    if keyword_filter:
        filtered_news = [news for news in filtered_news if any(kw in news['keywords'] for kw in keyword_filter)]
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_news = len(filtered_news)
        st.metric("ğŸ“° æ–°é—»æ€»æ•°", total_news)
    
    with col2:
        bullish_count = len([n for n in filtered_news if n['sentiment'] == 'åˆ©å¥½'])
        st.metric("ğŸ“ˆ åˆ©å¥½æ–°é—»", bullish_count, delta=f"{bullish_count/total_news*100:.0f}%" if total_news > 0 else "0%")
    
    with col3:
        bearish_count = len([n for n in filtered_news if n['sentiment'] == 'åˆ©ç©º'])
        st.metric("ğŸ“‰ åˆ©ç©ºæ–°é—»", bearish_count, delta=f"{bearish_count/total_news*100:.0f}%" if total_news > 0 else "0%")
    
    with col4:
        neutral_count = len([n for n in filtered_news if n['sentiment'] == 'ä¸­æ€§'])
        st.metric("ğŸ“Š ä¸­æ€§æ–°é—»", neutral_count, delta=f"{neutral_count/total_news*100:.0f}%" if total_news > 0 else "0%")
    
    # æƒ…ç»ªåˆ†ææ€»ç»“
    if total_news > 0:
        if bullish_count > bearish_count:
            overall_sentiment = "æ•´ä½“åå‘åˆ©å¥½"
            sentiment_color = "green"
            sentiment_icon = "ğŸ“ˆ"
        elif bearish_count > bullish_count:
            overall_sentiment = "æ•´ä½“åå‘åˆ©ç©º"
            sentiment_color = "red"
            sentiment_icon = "ğŸ“‰"
        else:
            overall_sentiment = "æƒ…ç»ªç›¸å¯¹å¹³è¡¡"
            sentiment_color = "gray"
            sentiment_icon = "ğŸ“Š"
        
        st.markdown(f"### {sentiment_icon} å¸‚åœºæƒ…ç»ªæ€»ç»“: <span style='color:{sentiment_color}'>{overall_sentiment}</span>", unsafe_allow_html=True)
    
    st.markdown("---")
    
    # æ˜¾ç¤ºæ–°é—»åˆ—è¡¨
    if len(filtered_news) > 0:
        st.subheader(f"ğŸ“° æœ€æ–°è´¢ç»æ–°é—» ({len(filtered_news)} æ¡)")
        
        for i, news in enumerate(filtered_news):
            # è·å–æƒ…ç»ªå»ºè®®
            impact_info = get_market_impact_advice(news['sentiment'])
            
            with st.container():
                # æ–°é—»å¡ç‰‡æ ·å¼
                col_main, col_side = st.columns([3, 1])
                
                with col_main:
                    # æ ‡é¢˜å’Œæ—¶é—´
                    time_str = news['published'].strftime('%Y-%m-%d %H:%M')
                    if news['is_real']:
                        st.markdown(f"### ğŸ“° {news['title']}")
                    else:
                        st.markdown(f"### â„¹ï¸ {news['title']}")
                    
                    st.caption(f"ğŸ•’ {time_str} | ğŸ“° {news['source']}")
                    
                    # æ‘˜è¦
                    st.write(news['summary'])
                    
                    # å…³é”®è¯
                    if news['keywords']:
                        keywords_str = " ".join([f"`{kw}`" for kw in news['keywords']])
                        st.markdown(f"**ğŸ” å…³é”®è¯:** {keywords_str}")
                    
                    # é“¾æ¥
                    if news['url']:
                        st.markdown(f"ğŸ”— [é˜…è¯»åŸæ–‡]({news['url']})")
                
                with col_side:
                    # æƒ…ç»ªåˆ†æ
                    sentiment_color = impact_info['color']
                    st.markdown(f"### {impact_info['icon']}")
                    st.markdown(f"**<span style='color:{sentiment_color}'>{news['sentiment']}</span>**", unsafe_allow_html=True)
                    
                    # æŠ•èµ„å»ºè®®
                    st.write(f"**ğŸ“‹ å½±å“:**")
                    st.write(impact_info['advice'])
                    
                    st.write(f"**ğŸ’¡ å»ºè®®:**")
                    st.write(impact_info['action'])
                
                st.markdown("---")
    
    else:
        st.info("ğŸ“­ æ ¹æ®å½“å‰ç­›é€‰æ¡ä»¶ï¼Œæš‚æ— ç›¸å…³æ–°é—»")

else:
    # æ¬¢è¿é¡µé¢
    st.markdown("""
    ## ğŸ¯ åŠŸèƒ½ä»‹ç»
    
    ### ğŸ“° å®æ—¶æ–°é—»è·å–
    - ğŸ“¡ ä»Yahoo Financeè·å–æœ€æ–°è´¢ç»æ–°é—»
    - ğŸ¯ æ”¯æŒç‰¹å®šè‚¡ç¥¨æ–°é—»å’Œå¸‚åœºæ•´ä½“æ–°é—»
    - ğŸ”„ è‡ªåŠ¨æ›´æ–°ï¼Œç¡®ä¿ä¿¡æ¯æ—¶æ•ˆæ€§
    
    ### ğŸŒ æ™ºèƒ½ä¸­æ–‡ç¿»è¯‘
    - ğŸ“ ä¸“ä¸šè´¢ç»æœ¯è¯­ç¿»è¯‘
    - ğŸ”¤ è‹±æ–‡å¥å‹ç»“æ„è½¬æ¢
    - ğŸ¯ ä¸Šä¸‹æ–‡è¯­å¢ƒç†è§£
    - ğŸš€ å¿«é€Ÿå“åº”ç¿»è¯‘
    
    ### ğŸ“Š æƒ…ç»ªåˆ†æç³»ç»Ÿ
    - ğŸ” å…³é”®è¯è‡ªåŠ¨æå–
    - ğŸ“ˆ å¤šç»´åº¦æƒ…ç»ªåˆ†æ
    - ğŸ’¡ æŠ•èµ„å½±å“è¯„ä¼°
    - ğŸ¯ æ“ä½œå»ºè®®ç”Ÿæˆ
    
    ### ğŸ”§ é«˜çº§ç­›é€‰åŠŸèƒ½
    - ğŸ˜Š æŒ‰æƒ…ç»ªç­›é€‰ (åˆ©å¥½/åˆ©ç©º/ä¸­æ€§)
    - ğŸ“… æŒ‰æ—¶é—´ç­›é€‰ (ä»Šæ—¥/è¿‘æœŸ/ä¸€å‘¨)
    - ğŸ·ï¸ æŒ‰å…³é”®è¯ç­›é€‰
    - ğŸ“Š ç»Ÿè®¡åˆ†æå±•ç¤º
    
    ---
    
    **ğŸ‘ˆ è¯·åœ¨å·¦ä¾§é€‰æ‹©è‚¡ç¥¨å¹¶ç‚¹å‡»"è·å–æœ€æ–°æ–°é—»"å¼€å§‹ä½¿ç”¨**
    
    **âš ï¸ å…è´£å£°æ˜:** æœ¬ç³»ç»Ÿä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚æŠ•èµ„æœ‰é£é™©ï¼Œå†³ç­–éœ€è°¨æ…ã€‚
    """)
    
    # ç¤ºä¾‹å±•ç¤º
    with st.expander("ğŸ¬ åŠŸèƒ½æ¼”ç¤º"):
        st.markdown("""
        ### ğŸ“Š æ–°é—»å±•ç¤ºç¤ºä¾‹
        
        **æ ‡é¢˜:** è‹¹æœå…¬å¸å®£å¸ƒæ–°ä¸€ä»£AIèŠ¯ç‰‡æŠ€æœ¯çªç ´
        
        **æ‘˜è¦:** è‹¹æœå…¬å¸åœ¨æœ€æ–°è´¢æŠ¥ä¸­é€éœ²ï¼Œå…¶è‡ªç ”çš„M4èŠ¯ç‰‡åœ¨AIå¤„ç†èƒ½åŠ›æ–¹é¢å–å¾—é‡å¤§çªç ´ï¼Œé¢„è®¡å°†æ˜¾è‘—æå‡Macå’ŒiPadäº§å“çš„äººå·¥æ™ºèƒ½è¡¨ç°...
        
        **å…³é”®è¯:** `ç§‘æŠ€` `äººå·¥æ™ºèƒ½` `èŠ¯ç‰‡` `ä¸Šæ¶¨`
        
        **æƒ…ç»ªåˆ†æ:** ğŸ“ˆ åˆ©å¥½
        
        **æŠ•èµ„å»ºè®®:** ç§¯æå› ç´ ï¼Œå¯å…³æ³¨ç›¸å…³æ¿å—æœºä¼šã€‚å»ºè®®å…³æ³¨ç›¸å…³æ¦‚å¿µè‚¡ï¼Œé€‚å½“å¢åŠ ä»“ä½ã€‚
        
        ---
        
        ### ğŸ” æ™ºèƒ½ç¿»è¯‘ç¤ºä¾‹
        
        **åŸæ–‡:** "Apple announced that its Q3 revenue increased by 15% year-over-year, beating expectations."
        
        **æ™ºèƒ½ç¿»è¯‘:** "è‹¹æœå®£å¸ƒå…¶ç¬¬ä¸‰å­£åº¦è¥æ”¶åŒæ¯”å¢é•¿15%ï¼Œè¶…é¢„æœŸã€‚"
        
        **å…³é”®è¯æå–:** è‹¹æœã€è¥æ”¶å¢é•¿ã€è¶…é¢„æœŸã€ä¸Šæ¶¨
        
        **æƒ…ç»ªåˆ¤æ–­:** åˆ©å¥½ â†’ æ¨èå…³æ³¨
        """)

# é¡µè„š
st.markdown("---")
st.markdown("ğŸ“° è´¢ç»æ–°é—»æ™ºèƒ½åˆ†æç³»ç»Ÿ | ğŸ”„ å®æ—¶æ–°é—» | ğŸŒ æ™ºèƒ½ç¿»è¯‘ | ğŸ“Š æƒ…ç»ªåˆ†æ | ğŸ’¡ æŠ•èµ„å»ºè®®")
