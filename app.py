import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
import warnings
import hashlib
import random
import time
import re
warnings.filterwarnings('ignore')

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ğŸ’¹ æ™ºèƒ½æŠ•èµ„åˆ†æç³»ç»Ÿ",
    page_icon="ğŸ’¹",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ– session state
if 'current_ticker' not in st.session_state:
    st.session_state.current_ticker = None
if 'current_price' not in st.session_state:
    st.session_state.current_price = 0
if 'analysis_data' not in st.session_state:
    st.session_state.analysis_data = None
if 'show_analysis' not in st.session_state:
    st.session_state.show_analysis = False

# æ ‡é¢˜
st.title("ğŸ’¹ æ™ºèƒ½æŠ•èµ„åˆ†æç³»ç»Ÿ v2.0")
st.markdown("---")

@st.cache_data(ttl=3600)
def fetch_stock_data(ticker):
    """è·å–è‚¡ç¥¨æ•°æ®"""
    try:
        stock = yf.Ticker(ticker)
        info = dict(stock.info)
        
        end_date = datetime.now()
        start_date = end_date - timedelta(days=365*2)
        hist_data = stock.history(start=start_date, end=end_date)
        
        financials = stock.financials
        balance_sheet = stock.balance_sheet
        cash_flow = stock.cashflow
        
        return {
            'info': info,
            'hist_data': hist_data.copy(),
            'financials': financials.copy() if financials is not None else pd.DataFrame(),
            'balance_sheet': balance_sheet.copy() if balance_sheet is not None else pd.DataFrame(),
            'cash_flow': cash_flow.copy() if cash_flow is not None else pd.DataFrame()
        }
    except Exception as e:
        st.error(f"è·å–æ•°æ®å¤±è´¥: {str(e)}")
        return None

def comprehensive_translate(text):
    """ç»¼åˆç¿»è¯‘ï¼šå¥å‹+è¯æ±‡ç¿»è¯‘"""
    if not text:
        return text
    
    # å…ˆè¿›è¡Œå¥å‹ç¿»è¯‘
    sentence_patterns = {
        # æ–°é—»å¼€å¤´å¸¸è§å¥å‹
        r'(\w+)\s+announced\s+that': r'\1å®£å¸ƒ',
        r'(\w+)\s+reported\s+that': r'\1æŠ¥å‘Šç§°',
        r'(\w+)\s+said\s+that': r'\1è¡¨ç¤º',
        r'(\w+)\s+revealed\s+that': r'\1é€éœ²',
        r'(\w+)\s+disclosed\s+that': r'\1æŠ«éœ²',
        r'(\w+)\s+confirmed\s+that': r'\1ç¡®è®¤',
        r'according\s+to\s+(\w+)': r'æ®\1',
        
        # è´¢æŠ¥ç›¸å…³å¥å‹
        r'(\w+)\s+posted\s+(\w+)\s+earnings': r'\1å…¬å¸ƒäº†\2è´¢æŠ¥',
        r'(\w+)\s+beat\s+earnings\s+expectations': r'\1è´¢æŠ¥è¶…é¢„æœŸ',
        r'(\w+)\s+missed\s+earnings\s+expectations': r'\1è´¢æŠ¥ä¸åŠé¢„æœŸ',
        r'(\w+)\s+reported\s+revenue\s+of\s+\$([0-9.]+)\s+billion': r'\1æŠ¥å‘Šè¥æ”¶\2åäº¿ç¾å…ƒ',
        r'(\w+)\s+reported\s+revenue\s+of\s+\$([0-9.]+)\s+million': r'\1æŠ¥å‘Šè¥æ”¶\2ç™¾ä¸‡ç¾å…ƒ',
        r'revenue\s+increased\s+by\s+([0-9.]+)%': r'è¥æ”¶å¢é•¿\1%',
        r'revenue\s+decreased\s+by\s+([0-9.]+)%': r'è¥æ”¶ä¸‹é™\1%',
        
        # è‚¡ä»·ç›¸å…³å¥å‹
        r'(\w+)\s+shares\s+rose\s+([0-9.]+)%': r'\1è‚¡ä»·ä¸Šæ¶¨\2%',
        r'(\w+)\s+shares\s+fell\s+([0-9.]+)%': r'\1è‚¡ä»·ä¸‹è·Œ\2%',
        r'(\w+)\s+shares\s+gained\s+([0-9.]+)%': r'\1è‚¡ä»·ä¸Šæ¶¨\2%',
        r'(\w+)\s+shares\s+dropped\s+([0-9.]+)%': r'\1è‚¡ä»·ä¸‹è·Œ\2%',
        r'shares\s+closed\s+at\s+\$([0-9.]+)': r'è‚¡ä»·æ”¶äº\1ç¾å…ƒ',
        
        # å…¬å¸è¡ŒåŠ¨å¥å‹
        r'(\w+)\s+will\s+acquire\s+(\w+)': r'\1å°†æ”¶è´­\2',
        r'(\w+)\s+acquired\s+(\w+)': r'\1æ”¶è´­äº†\2',
        r'(\w+)\s+launched\s+a?\s*new\s+(\w+)': r'\1æ¨å‡ºæ–°\2',
        r'(\w+)\s+introduced\s+(\w+)': r'\1æ¨å‡º\2',
        r'(\w+)\s+unveiled\s+(\w+)': r'\1å‘å¸ƒ\2',
        r'(\w+)\s+plans\s+to\s+(\w+)': r'\1è®¡åˆ’\2',
        r'(\w+)\s+expects\s+to\s+(\w+)': r'\1é¢„è®¡å°†\2',
        r'(\w+)\s+is\s+expected\s+to\s+(\w+)': r'\1é¢„è®¡å°†\2',
        
        # æ—¶é—´è¡¨è¾¾
        r'this\s+quarter': 'æœ¬å­£åº¦',
        r'last\s+quarter': 'ä¸Šå­£åº¦',
        r'this\s+year': 'ä»Šå¹´',
        r'last\s+year': 'å»å¹´',
        r'compared\s+to\s+last\s+year': 'ä¸å»å¹´ç›¸æ¯”',
        r'year-over-year': 'åŒæ¯”',
        
        # å¸¸è§çŸ­è¯­
        r'beat\s+expectations': 'è¶…é¢„æœŸ',
        r'missed\s+expectations': 'ä¸åŠé¢„æœŸ',
        r'better\s+than\s+expected': 'å¥½äºé¢„æœŸ',
        r'record\s+high': 'å†å²æ–°é«˜',
        r'all-time\s+high': 'å†å²æœ€é«˜',
        
        # æ•°å­—è¡¨è¾¾
        r'\$([0-9.]+)\s+billion': r'\1åäº¿ç¾å…ƒ',
        r'\$([0-9.]+)\s+million': r'\1ç™¾ä¸‡ç¾å…ƒ',
        r'([0-9.]+)\s+billion': r'\1åäº¿',
        r'([0-9.]+)\s+million': r'\1ç™¾ä¸‡',
        
        # è¡Œä¸šæœ¯è¯­
        r'artificial\s+intelligence': 'äººå·¥æ™ºèƒ½',
        r'machine\s+learning': 'æœºå™¨å­¦ä¹ ',
        r'cloud\s+computing': 'äº‘è®¡ç®—',
        r'electric\s+vehicles?': 'ç”µåŠ¨æ±½è½¦',
        r'renewable\s+energy': 'å¯å†ç”Ÿèƒ½æº',
    }
    
    result = text
    
    # åº”ç”¨å¥å‹ç¿»è¯‘
    for pattern, replacement in sentence_patterns.items():
        result = re.sub(pattern, replacement, result, flags=re.IGNORECASE)
    
    # ç„¶ååº”ç”¨åŸºç¡€è¯æ±‡ç¿»è¯‘
    result = basic_financial_translate(result)
    
    return result

def basic_financial_translate(text):
    """åŸºç¡€è´¢ç»æœ¯è¯­ç¿»è¯‘"""
    if not text:
        return text
    
    financial_dict = {
        # å…¬å¸åç§°
        'Apple Inc': 'è‹¹æœå…¬å¸',
        'Apple': 'è‹¹æœå…¬å¸',
        'Tesla Inc': 'ç‰¹æ–¯æ‹‰å…¬å¸', 
        'Tesla': 'ç‰¹æ–¯æ‹‰å…¬å¸',
        'Microsoft Corporation': 'å¾®è½¯å…¬å¸',
        'Microsoft': 'å¾®è½¯å…¬å¸',
        'Amazon.com Inc': 'äºšé©¬é€Šå…¬å¸',
        'Amazon': 'äºšé©¬é€Šå…¬å¸',
        'Google': 'è°·æ­Œ',
        'Meta': 'Metaå…¬å¸',
        'NVIDIA': 'è‹±ä¼Ÿè¾¾',
        'Netflix': 'å¥ˆé£',
        'Facebook': 'è„¸ä¹¦',
        
        # è‚¡ç¥¨ä»£ç 
        'AAPL': 'è‹¹æœ(AAPL)',
        'TSLA': 'ç‰¹æ–¯æ‹‰(TSLA)',
        'MSFT': 'å¾®è½¯(MSFT)',
        'AMZN': 'äºšé©¬é€Š(AMZN)',
        'GOOGL': 'è°·æ­Œ(GOOGL)',
        'META': 'Meta(META)',
        'NVDA': 'è‹±ä¼Ÿè¾¾(NVDA)',
        'NFLX': 'å¥ˆé£(NFLX)',
        
        # è´¢ç»æœ¯è¯­
        'earnings report': 'è´¢æŠ¥',
        'quarterly earnings': 'å­£åº¦è´¢æŠ¥',
        'revenue': 'è¥æ”¶',
        'profit': 'åˆ©æ¶¦',
        'loss': 'äºæŸ',
        'dividend': 'åˆ†çº¢',
        'stock price': 'è‚¡ä»·',
        'market cap': 'å¸‚å€¼',
        'investment': 'æŠ•èµ„',
        'investor': 'æŠ•èµ„è€…',
        'shareholder': 'è‚¡ä¸œ',
        'CEO': 'é¦–å¸­æ‰§è¡Œå®˜',
        'CFO': 'é¦–å¸­è´¢åŠ¡å®˜',
        
        # åŸºç¡€è¯æ±‡
        'technology': 'ç§‘æŠ€',
        'artificial intelligence': 'äººå·¥æ™ºèƒ½',
        'AI': 'äººå·¥æ™ºèƒ½',
        'semiconductor': 'åŠå¯¼ä½“',
        'electric vehicle': 'ç”µåŠ¨æ±½è½¦',
        'cloud computing': 'äº‘è®¡ç®—',
        'e-commerce': 'ç”µå­å•†åŠ¡',
        'streaming': 'æµåª’ä½“',
        
        # æ•°å€¼è¡¨è¾¾
        'billion': 'åäº¿',
        'million': 'ç™¾ä¸‡',
        'percent': 'ç™¾åˆ†æ¯”',
        
        # å¸‚åœºåŠ¨ä½œ
        'announced': 'å®£å¸ƒ',
        'reported': 'æŠ¥å‘Š',
        'released': 'å‘å¸ƒ',
        'launched': 'æ¨å‡º',
        'acquired': 'æ”¶è´­',
        'merged': 'åˆå¹¶',
        
        # å…¶ä»–å¸¸ç”¨è¯
        'growth': 'å¢é•¿',
        'decline': 'ä¸‹é™',
        'increase': 'å¢åŠ ',
        'decrease': 'å‡å°‘',
        'performance': 'è¡¨ç°',
        'results': 'ç»“æœ',
        'forecast': 'é¢„æµ‹',
        'outlook': 'å±•æœ›',
        'guidance': 'æŒ‡å¯¼',
        'target': 'ç›®æ ‡',
        
        # å®Œæ•´å¥å¼
        'said in a statement': 'åœ¨å£°æ˜ä¸­è¡¨ç¤º',
        'according to': 'æ®',
        'is expected to': 'é¢„è®¡å°†',
        'announced today': 'ä»Šæ—¥å®£å¸ƒ',
        'shares rose': 'è‚¡ä»·ä¸Šæ¶¨',
        'shares fell': 'è‚¡ä»·ä¸‹è·Œ',
        'revenue growth': 'è¥æ”¶å¢é•¿',
        'net income': 'å‡€åˆ©æ¶¦',
        'cash flow': 'ç°é‡‘æµ',
        'market value': 'å¸‚å€¼',
        'stock market': 'è‚¡å¸‚',
        'board of directors': 'è‘£äº‹ä¼š',
        'supply chain': 'ä¾›åº”é“¾',
        'research and development': 'ç ”å‘',
        'initial public offering': 'é¦–æ¬¡å…¬å¼€å‹Ÿè‚¡',
        'mergers and acquisitions': 'å¹¶è´­',
    }
    
    result = text
    for en, zh in financial_dict.items():
        pattern = r'\b' + re.escape(en) + r'\b'
        result = re.sub(pattern, zh, result, flags=re.IGNORECASE)
    
    return result

def translate_with_google_alternative(text):
    """ä½¿ç”¨Googleç¿»è¯‘çš„æ›¿ä»£æ¥å£ï¼ˆå¿«é€Ÿç‰ˆæœ¬ï¼‰"""
    try:
        import requests
        
        url = "https://translate.google.cn/translate_a/single"
        params = {
            'client': 'gtx',
            'sl': 'en',
            'tl': 'zh',
            'dt': 't',
            'q': text[:500]
        }
        
        headers = {
            'User-Agent': 'Mozilla/5.0'
        }
        
        response = requests.get(url, params=params, headers=headers, timeout=3)
        if response.status_code == 200:
            result = response.json()
            if result and len(result) > 0 and result[0]:
                translated_parts = []
                for item in result[0]:
                    if item and len(item) > 0 and item[0]:
                        translated_parts.append(item[0])
                if translated_parts:
                    return ''.join(translated_parts)
    except:
        pass
    return None

def smart_translate(text):
    """æ™ºèƒ½ç¿»è¯‘ï¼šä¼˜å…ˆä½¿ç”¨ç»¼åˆç¿»è¯‘"""
    if not text or len(text.strip()) < 3:
        return text
    
    # ä½¿ç”¨ç»¼åˆç¿»è¯‘
    translated = comprehensive_translate(text)
    
    # å¦‚æœç¿»è¯‘æ•ˆæœè¿˜æ˜¯ä¸å¤Ÿå¥½ï¼Œå°è¯•åœ¨çº¿ç¿»è¯‘ï¼ˆä»…é™çŸ­æ–‡æœ¬ï¼‰
    if len(text) < 200 and translated == text:
        try:
            online_result = translate_with_google_alternative(text)
            if online_result and len(online_result.strip()) > 5:
                return online_result
        except:
            pass
    
    return translated

def fetch_financial_news(target_ticker=None):
    """è·å–çœŸå®è´¢ç»æ–°é—»ï¼ˆä»…çœŸå®æ–°é—»ï¼‰"""
    try:
        current_time = datetime.now()
        news_data = []
        
        # è·å–ç›®æ ‡è‚¡ç¥¨æ–°é—»
        if target_ticker:
            try:
                ticker_obj = yf.Ticker(target_ticker)
                news = ticker_obj.news
                
                if news and len(news) > 0:
                    for i, article in enumerate(news[:8]):
                        try:
                            content = article.get('content', article)
                            
                            title = content.get('title', '') or content.get('headline', '') or article.get('title', '')
                            summary = content.get('summary', '') or content.get('description', '') or content.get('snippet', '')
                            
                            # è·å–é“¾æ¥
                            link = ''
                            if 'clickThroughUrl' in content and content['clickThroughUrl']:
                                link = content['clickThroughUrl'].get('url', '')
                            elif 'canonicalUrl' in content and content['canonicalUrl']:
                                link = content['canonicalUrl'].get('url', '')
                            else:
                                link = content.get('link', '') or content.get('url', '')
                            
                            # è·å–å‘å¸ƒè€…
                            publisher = 'Unknown'
                            if 'provider' in content and content['provider']:
                                publisher = content['provider'].get('displayName', 'Unknown')
                            else:
                                publisher = content.get('publisher', '') or content.get('source', 'Unknown')
                            
                            # è·å–æ—¶é—´
                            pub_date_str = content.get('pubDate', '') or content.get('displayTime', '')
                            if pub_date_str:
                                try:
                                    if 'T' in pub_date_str and 'Z' in pub_date_str:
                                        published_time = datetime.fromisoformat(pub_date_str.replace('Z', '+00:00')).replace(tzinfo=None)
                                    else:
                                        published_time = current_time - timedelta(hours=i+1)
                                except:
                                    published_time = current_time - timedelta(hours=i+1)
                            else:
                                pub_time = content.get('providerPublishTime', None) or article.get('providerPublishTime', None)
                                if pub_time:
                                    try:
                                        published_time = datetime.fromtimestamp(pub_time)
                                    except:
                                        published_time = current_time - timedelta(hours=i+1)
                                else:
                                    published_time = current_time - timedelta(hours=i+1)
                            
                            if title and len(title.strip()) > 5:
                                # ç¿»è¯‘æ ‡é¢˜å’Œæ‘˜è¦
                                try:
                                    translated_title = smart_translate(title)
                                    if summary and len(summary.strip()) > 10:
                                        if len(summary) > 400:
                                            summary = summary[:400] + "..."
                                        translated_summary = smart_translate(summary)
                                    else:
                                        translated_summary = 'æš‚æ— æ‘˜è¦'
                                except:
                                    translated_title = basic_financial_translate(title)
                                    translated_summary = basic_financial_translate(summary) if summary else 'æš‚æ— æ‘˜è¦'
                                
                                # æå–å…³é”®è¯å’Œåˆ†ææƒ…ç»ª
                                title_summary = title + ' ' + (summary or '')
                                keywords = extract_keywords_from_text(title_summary)
                                sentiment = analyze_sentiment_from_keywords(keywords)
                                
                                news_item = {
                                    "title": translated_title,
                                    "summary": translated_summary[:300] + '...' if len(translated_summary) > 300 else translated_summary,
                                    "published": published_time,
                                    "url": link or '',
                                    "source": publisher,
                                    "category": "company_specific",
                                    "keywords": keywords,
                                    "sentiment": sentiment,
                                    "is_real": True
                                }
                                news_data.append(news_item)
                        except Exception as e:
                            continue
            except Exception as e:
                pass
        
        # è·å–å¸‚åœºæ•´ä½“æ–°é—»
        try:
            market_indices = ["^GSPC", "^IXIC", "^DJI"]
            for index_symbol in market_indices:
                try:
                    index_ticker = yf.Ticker(index_symbol)
                    index_news = index_ticker.news
                    
                    if index_news and len(index_news) > 0:
                        for j, article in enumerate(index_news[:3]):
                            try:
                                content = article.get('content', article)
                                
                                title = content.get('title', '') or content.get('headline', '') or article.get('title', '')
                                summary = content.get('summary', '') or content.get('description', '') or content.get('snippet', '')
                                
                                # è·å–é“¾æ¥
                                link = ''
                                if 'clickThroughUrl' in content and content['clickThroughUrl']:
                                    link = content['clickThroughUrl'].get('url', '')
                                elif 'canonicalUrl' in content and content['canonicalUrl']:
                                    link = content['canonicalUrl'].get('url', '')
                                else:
                                    link = content.get('link', '') or content.get('url', '')
                                
                                # è·å–å‘å¸ƒè€…
                                publisher = 'Market News'
                                if 'provider' in content and content['provider']:
                                    publisher = content['provider'].get('displayName', 'Market News')
                                else:
                                    publisher = content.get('publisher', '') or content.get('source', 'Market News')
                                
                                # è·å–æ—¶é—´
                                pub_date_str = content.get('pubDate', '') or content.get('displayTime', '')
                                if pub_date_str:
                                    try:
                                        if 'T' in pub_date_str and 'Z' in pub_date_str:
                                            published_time = datetime.fromisoformat(pub_date_str.replace('Z', '+00:00')).replace(tzinfo=None)
                                        else:
                                            published_time = current_time - timedelta(hours=len(news_data)+1)
                                    except:
                                        published_time = current_time - timedelta(hours=len(news_data)+1)
                                else:
                                    published_time = current_time - timedelta(hours=len(news_data)+1)
                                
                                if title and len(title.strip()) > 5:
                                    # é¿å…é‡å¤æ–°é—»
                                    if not any(existing['title'] == title for existing in news_data):
                                        try:
                                            translated_title = smart_translate(title)
                                            if summary and len(summary.strip()) > 10:
                                                if len(summary) > 400:
                                                    summary = summary[:400] + "..."
                                                translated_summary = smart_translate(summary)
                                            else:
                                                translated_summary = 'æš‚æ— æ‘˜è¦'
                                        except:
                                            translated_title = basic_financial_translate(title)
                                            translated_summary = basic_financial_translate(summary) if summary else 'æš‚æ— æ‘˜è¦'
                                        
                                        title_summary = title + ' ' + (summary or '')
                                        keywords = extract_keywords_from_text(title_summary)
                                        sentiment = analyze_sentiment_from_keywords(keywords)
                                        
                                        news_item = {
                                            "title": translated_title,
                                            "summary": translated_summary[:300] + '...' if len(translated_summary) > 300 else translated_summary,
                                            "published": published_time,
                                            "url": link or '',
                                            "source": publisher,
                                            "category": "market_wide",
                                            "keywords": keywords,
                                            "sentiment": sentiment,
                                            "is_real": True
                                        }
                                        news_data.append(news_item)
                            except Exception as e:
                                continue
                except Exception as e:
                    continue
        except Exception as e:
            pass
        
        # æŒ‰æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
        news_data.sort(key=lambda x: x.get('published', datetime.now()), reverse=True)
        
        # å¦‚æœä»ç„¶æ²¡æœ‰æ–°é—»ï¼Œæä¾›ç³»ç»Ÿæç¤º
        if len(news_data) == 0:
            return [{
                "title": "æ–°é—»è·å–æœåŠ¡æš‚æ—¶ä¸å¯ç”¨",
                "summary": "ç”±äºæŠ€æœ¯åŸå› ï¼Œæš‚æ—¶æ— æ³•è·å–å®æ—¶è´¢ç»æ–°é—»ã€‚è¯·ç›´æ¥è®¿é—®Yahoo Financeã€Bloombergç­‰è´¢ç»ç½‘ç«™è·å–æœ€æ–°å¸‚åœºä¿¡æ¯ã€‚",
                "published": current_time,
                "url": "https://finance.yahoo.com",
                "source": "ç³»ç»Ÿæç¤º",
                "category": "system_info",
                "keywords": ["ç³»ç»Ÿ", "æç¤º"],
                "sentiment": "ä¸­æ€§",
                "is_real": False
            }]
        
        return news_data
        
    except Exception as e:
        return [{
            "title": "æ–°é—»è·å–æœåŠ¡æš‚æ—¶ä¸å¯ç”¨",
            "summary": "ç”±äºæŠ€æœ¯åŸå› ï¼Œæš‚æ—¶æ— æ³•è·å–å®æ—¶è´¢ç»æ–°é—»ã€‚è¯·ç›´æ¥è®¿é—®è´¢ç»ç½‘ç«™è·å–æœ€æ–°å¸‚åœºä¿¡æ¯ã€‚",
            "published": datetime.now(),
            "url": "",
            "source": "ç³»ç»Ÿ",
            "category": "system_info",
            "keywords": ["ç³»ç»Ÿ"],
            "sentiment": "ä¸­æ€§",
            "is_real": False
        }]

def extract_keywords_from_text(text):
    """ä»æ–‡æœ¬ä¸­æå–è´¢ç»å…³é”®è¯"""
    if not text:
        return []
    
    text_lower = text.lower()
    
    keyword_categories = {
        "åˆ©ç‡": ["rate", "interest", "fed", "federal reserve", "åˆ©ç‡", "é™æ¯", "åŠ æ¯"],
        "ç§‘æŠ€": ["tech", "technology", "ai", "artificial intelligence", "chip", "semiconductor", "ç§‘æŠ€", "äººå·¥æ™ºèƒ½", "èŠ¯ç‰‡"],
        "é‡‘è": ["bank", "financial", "finance", "credit", "loan", "é“¶è¡Œ", "é‡‘è", "ä¿¡è´·"],
        "èƒ½æº": ["energy", "oil", "gas", "petroleum", "renewable", "èƒ½æº", "çŸ³æ²¹", "å¤©ç„¶æ°”"],
        "ä¸Šæ¶¨": ["up", "rise", "gain", "increase", "rally", "surge", "ä¸Šæ¶¨", "å¢é•¿", "ä¸Šå‡"],
        "ä¸‹è·Œ": ["down", "fall", "drop", "decline", "crash", "ä¸‹è·Œ", "ä¸‹é™", "æš´è·Œ"],
        "é€šèƒ€": ["inflation", "cpi", "consumer price", "é€šèƒ€", "ç‰©ä»·"],
        "æ”¿ç­–": ["policy", "regulation", "government", "æ”¿ç­–", "ç›‘ç®¡", "æ”¿åºœ"],
        "ç»æµå¢é•¿": ["growth", "gdp", "economic", "economy", "ç»æµ", "å¢é•¿"],
        "å¸‚åœº": ["market", "stock", "trading", "investor", "å¸‚åœº", "è‚¡ç¥¨", "æŠ•èµ„"]
    }
    
    found_keywords = []
    for category, words in keyword_categories.items():
        for word in words:
            if word in text_lower:
                found_keywords.append(category)
                break
    
    return found_keywords[:5]

def analyze_sentiment_from_keywords(keywords):
    """æ ¹æ®å…³é”®è¯åˆ†ææƒ…ç»ª"""
    bullish_words = ["ä¸Šæ¶¨", "å¢é•¿", "åˆ©ç‡", "ç§‘æŠ€", "ç»æµå¢é•¿"]
    bearish_words = ["ä¸‹è·Œ", "é€šèƒ€", "æ”¿ç­–"]
    
    bullish_count = sum(1 for kw in keywords if kw in bullish_words)
    bearish_count = sum(1 for kw in keywords if kw in bearish_words)
    
    if bullish_count > bearish_count:
        return "åˆ©å¥½"
    elif bearish_count > bullish_count:
        return "åˆ©ç©º"
    else:
        return "ä¸­æ€§"

def get_market_impact_advice(sentiment):
    """æ ¹æ®æƒ…ç»ªç»™å‡ºå¸‚åœºå½±å“å»ºè®®"""
    if sentiment == "åˆ©å¥½":
        return {
            "icon": "ğŸ“ˆ",
            "advice": "ç§¯æå› ç´ ï¼Œå¯å…³æ³¨ç›¸å…³æ¿å—æœºä¼š",
            "action": "å»ºè®®å…³æ³¨ç›¸å…³æ¦‚å¿µè‚¡ï¼Œé€‚å½“å¢åŠ ä»“ä½"
        }
    elif sentiment == "åˆ©ç©º":
        return {
            "icon": "ğŸ“‰", 
            "advice": "é£é™©å› ç´ ï¼Œå»ºè®®è°¨æ…æ“ä½œ",
            "action": "é™ä½é£é™©æ•å£ï¼Œå…³æ³¨é˜²å¾¡æ€§æ¿å—"
        }
    else:
        return {
            "icon": "ğŸ“Š",
            "advice": "ä¸­æ€§å½±å“ï¼Œç»´æŒç°æœ‰ç­–ç•¥",
            "action": "å¯†åˆ‡å…³æ³¨åç»­å‘å±•ï¼Œä¿æŒçµæ´»æ“ä½œ"
        }

def calculate_technical_indicators(hist_data):
    """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡"""
    try:
        hist_data['MA10'] = hist_data['Close'].rolling(window=10).mean()
        hist_data['MA20'] = hist_data['Close'].rolling(window=20).mean()
        hist_data['MA60'] = hist_data['Close'].rolling(window=60).mean()
        
        exp1 = hist_data['Close'].ewm(span=12, adjust=False).mean()
        exp2 = hist_data['Close'].ewm(span=26, adjust=False).mean()
        hist_data['MACD'] = exp1 - exp2
        hist_data['Signal'] = hist_data['MACD'].ewm(span=9, adjust=False).mean()
        hist_data['MACD_Histogram'] = hist_data['MACD'] - hist_data['Signal']
        
        delta = hist_data['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        hist_data['RSI'] = 100 - (100 / (1 + rs))
        
        hist_data['BB_Middle'] = hist_data['Close'].rolling(window=20).mean()
        bb_std = hist_data['Close'].rolling(window=20).std()
        hist_data['BB_Upper'] = hist_data['BB_Middle'] + (bb_std * 2)
        hist_data['BB_Lower'] = hist_data['BB_Middle'] - (bb_std * 2)
        
        return hist_data
    except Exception as e:
        st.warning(f"æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¤±è´¥: {str(e)}")
        return hist_data

def calculate_piotroski_score(data):
    """è®¡ç®—Piotroski F-Score"""
    score = 0
    reasons = []
    
    try:
        financials = data['financials']
        balance_sheet = data['balance_sheet']
        cash_flow = data['cash_flow']
        
        if financials.empty or balance_sheet.empty or cash_flow.empty:
            return 0, ["âŒ è´¢åŠ¡æ•°æ®ä¸å®Œæ•´"]
        
        # 1. å‡€åˆ©æ¶¦
        if len(financials.columns) >= 1 and 'Net Income' in financials.index:
            net_income = financials.loc['Net Income'].iloc[0]
            if net_income > 0:
                score += 1
                reasons.append("âœ… å‡€åˆ©æ¶¦ä¸ºæ­£")
            else:
                reasons.append("âŒ å‡€åˆ©æ¶¦ä¸ºè´Ÿ")
        
        # 2. ç»è¥ç°é‡‘æµ
        if len(cash_flow.columns) >= 1 and 'Operating Cash Flow' in cash_flow.index:
            ocf = cash_flow.loc['Operating Cash Flow'].iloc[0]
            if ocf > 0:
                score += 1
                reasons.append("âœ… ç»è¥ç°é‡‘æµä¸ºæ­£")
            else:
                reasons.append("âŒ ç»è¥ç°é‡‘æµä¸ºè´Ÿ")
        
        # ç®€åŒ–å…¶ä»–æŒ‡æ ‡
        score += 5
        reasons.append("ğŸ“Š å…¶ä»–è´¢åŠ¡æŒ‡æ ‡åŸºç¡€åˆ†: 5åˆ†")
        
    except Exception as e:
        return 0, ["âŒ è®¡ç®—è¿‡ç¨‹å‡ºç°é”™è¯¯"]
    
    return score, reasons

def calculate_dcf_valuation(data):
    """DCFä¼°å€¼æ¨¡å‹"""
    try:
        info = data['info']
        cash_flow = data['cash_flow']
        
        if cash_flow.empty:
            return None, None
        
        # è·å–è‡ªç”±ç°é‡‘æµ
        fcf = 0
        if 'Free Cash Flow' in cash_flow.index and len(cash_flow.columns) > 0:
            fcf = cash_flow.loc['Free Cash Flow'].iloc[0]
        elif 'Operating Cash Flow' in cash_flow.index and len(cash_flow.columns) > 0:
            ocf = cash_flow.loc['Operating Cash Flow'].iloc[0]
            capex = cash_flow.loc['Capital Expenditure'].iloc[0] if 'Capital Expenditure' in cash_flow.index else 0
            fcf = ocf + capex
