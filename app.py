import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
import re
import requests
import time
import json
warnings.filterwarnings('ignore')

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ğŸ“° é€šç”¨ç¾è‚¡æ–°é—»åˆ†æç³»ç»Ÿ",
    page_icon="ğŸ“°",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ– session state
if 'selected_ticker' not in st.session_state:
    st.session_state.selected_ticker = None
if 'news_data' not in st.session_state:
    st.session_state.news_data = None

st.title("ğŸ“° é€šç”¨ç¾è‚¡æ–°é—»åˆ†æç³»ç»Ÿ")
st.markdown("**æ”¯æŒæ‰€æœ‰ç¾è‚¡ä»£ç  + å®æ—¶æ–°é—»è·å– + æ™ºèƒ½ä¸­æ–‡ç¿»è¯‘ + æƒ…ç»ªåˆ†æ**")
st.markdown("---")

# ==================== é€šç”¨ç¿»è¯‘ç³»ç»Ÿ ====================

def create_dynamic_translation_dict():
    """åˆ›å»ºåŠ¨æ€è´¢ç»ç¿»è¯‘è¯å…¸"""
    return {
        # é€šç”¨è´¢ç»æœ¯è¯­
        'earnings': 'è´¢æŠ¥', 'revenue': 'è¥æ”¶', 'profit': 'åˆ©æ¶¦', 'loss': 'äºæŸ',
        'dividend': 'åˆ†çº¢', 'stock': 'è‚¡ç¥¨', 'shares': 'è‚¡ä»½', 'price': 'ä»·æ ¼',
        'market': 'å¸‚åœº', 'trading': 'äº¤æ˜“', 'investor': 'æŠ•èµ„è€…', 'investment': 'æŠ•èµ„',
        'shareholder': 'è‚¡ä¸œ', 'CEO': 'é¦–å¸­æ‰§è¡Œå®˜', 'CFO': 'é¦–å¸­è´¢åŠ¡å®˜',
        
        # å¸‚åœºåŠ¨ä½œ
        'announced': 'å®£å¸ƒ', 'reported': 'æŠ¥å‘Š', 'released': 'å‘å¸ƒ', 'launched': 'æ¨å‡º',
        'acquired': 'æ”¶è´­', 'merged': 'åˆå¹¶', 'expanded': 'æ‰©å¼ ', 'increased': 'å¢åŠ ',
        'decreased': 'å‡å°‘', 'grew': 'å¢é•¿', 'fell': 'ä¸‹è·Œ', 'rose': 'ä¸Šæ¶¨',
        'gained': 'ä¸Šæ¶¨', 'dropped': 'ä¸‹è·Œ', 'surged': 'é£™å‡', 'plunged': 'æš´è·Œ',
        
        # è¡Œä¸šæœ¯è¯­
        'technology': 'ç§‘æŠ€', 'artificial intelligence': 'AI', 'machine learning': 'æœºå™¨å­¦ä¹ ',
        'cloud computing': 'äº‘è®¡ç®—', 'semiconductor': 'åŠå¯¼ä½“', 'software': 'è½¯ä»¶',
        'hardware': 'ç¡¬ä»¶', 'electric vehicle': 'ç”µåŠ¨æ±½è½¦', 'renewable energy': 'å¯å†ç”Ÿèƒ½æº',
        'healthcare': 'åŒ»ç–—ä¿å¥', 'pharmaceutical': 'åˆ¶è¯', 'biotechnology': 'ç”Ÿç‰©æŠ€æœ¯',
        'financial services': 'é‡‘èæœåŠ¡', 'banking': 'é“¶è¡Œä¸š', 'insurance': 'ä¿é™©',
        'real estate': 'æˆ¿åœ°äº§', 'retail': 'é›¶å”®', 'e-commerce': 'ç”µå•†',
        
        # æ•°å€¼è¡¨è¾¾
        'billion': 'åäº¿', 'million': 'ç™¾ä¸‡', 'thousand': 'åƒ', 'percent': 'ç™¾åˆ†æ¯”',
        'quarterly': 'å­£åº¦', 'annually': 'å¹´åº¦', 'monthly': 'æœˆåº¦',
        
        # æ—¶é—´è¡¨è¾¾
        'this quarter': 'æœ¬å­£åº¦', 'last quarter': 'ä¸Šå­£åº¦', 'this year': 'ä»Šå¹´',
        'last year': 'å»å¹´', 'year-over-year': 'åŒæ¯”', 'quarter-over-quarter': 'ç¯æ¯”',
        
        # å¸¸è§è¡¨è¾¾
        'beat expectations': 'è¶…é¢„æœŸ', 'missed expectations': 'ä¸åŠé¢„æœŸ',
        'better than expected': 'å¥½äºé¢„æœŸ', 'worse than expected': 'å·®äºé¢„æœŸ',
        'record high': 'å†å²æ–°é«˜', 'all-time high': 'å†å²æœ€é«˜',
        'record low': 'å†å²æ–°ä½', 'all-time low': 'å†å²æœ€ä½',
        
        # å¥å‹æ¨¡å¼
        'said in a statement': 'åœ¨å£°æ˜ä¸­è¡¨ç¤º', 'according to': 'æ®',
        'is expected to': 'é¢„è®¡å°†', 'announced today': 'ä»Šæ—¥å®£å¸ƒ',
        'plans to': 'è®¡åˆ’', 'aims to': 'æ—¨åœ¨', 'seeks to': 'å¯»æ±‚',
    }

def smart_universal_translate(text):
    """é€šç”¨æ™ºèƒ½ç¿»è¯‘ç³»ç»Ÿ"""
    if not text or len(text.strip()) < 3:
        return text
    
    # è·å–åŠ¨æ€ç¿»è¯‘è¯å…¸
    translation_dict = create_dynamic_translation_dict()
    
    result = text
    
    # åº”ç”¨é€šç”¨ç¿»è¯‘
    for en_term, zh_term in translation_dict.items():
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œå•è¯è¾¹ç•ŒåŒ¹é…
        pattern = r'\b' + re.escape(en_term) + r'\b'
        result = re.sub(pattern, zh_term, result, flags=re.IGNORECASE)
    
    # å¤„ç†æ•°å­—+å•ä½çš„è¡¨è¾¾
    # $X billion -> Xåäº¿ç¾å…ƒ
    result = re.sub(r'\$([0-9.]+)\s*billion', r'\1åäº¿ç¾å…ƒ', result, flags=re.IGNORECASE)
    result = re.sub(r'\$([0-9.]+)\s*million', r'\1ç™¾ä¸‡ç¾å…ƒ', result, flags=re.IGNORECASE)
    result = re.sub(r'([0-9.]+)%', r'\1%', result)
    
    # å¤„ç†å¸¸è§å¥å‹
    sentence_patterns = {
        r'(\w+)\s+announced\s+that': r'\1å®£å¸ƒ',
        r'(\w+)\s+reported\s+that': r'\1æŠ¥å‘Šç§°',
        r'(\w+)\s+said\s+that': r'\1è¡¨ç¤º',
        r'shares\s+of\s+(\w+)\s+rose\s+([0-9.]+)%': r'\1è‚¡ä»·ä¸Šæ¶¨\2%',
        r'shares\s+of\s+(\w+)\s+fell\s+([0-9.]+)%': r'\1è‚¡ä»·ä¸‹è·Œ\2%',
        r'(\w+)\s+beat\s+earnings\s+expectations': r'\1è´¢æŠ¥è¶…é¢„æœŸ',
        r'(\w+)\s+missed\s+earnings\s+expectations': r'\1è´¢æŠ¥ä¸åŠé¢„æœŸ',
    }
    
    for pattern, replacement in sentence_patterns.items():
        result = re.sub(pattern, replacement, result, flags=re.IGNORECASE)
    
    return result

def extract_universal_keywords(text):
    """é€šç”¨å…³é”®è¯æå–"""
    if not text:
        return []
    
    text_lower = text.lower()
    
    keyword_categories = {
        "ç§‘æŠ€": ["tech", "technology", "ai", "artificial intelligence", "software", "hardware", 
                "cloud", "semiconductor", "chip", "digital", "innovation"],
        "é‡‘è": ["bank", "financial", "finance", "credit", "loan", "insurance", "investment"],
        "åŒ»ç–—": ["health", "medical", "pharmaceutical", "biotech", "drug", "vaccine"],
        "èƒ½æº": ["energy", "oil", "gas", "renewable", "solar", "wind", "electric"],
        "æ¶ˆè´¹": ["retail", "consumer", "sales", "ecommerce", "shopping"],
        "æˆ¿åœ°äº§": ["real estate", "property", "housing", "construction"],
        "ä¸Šæ¶¨": ["up", "rise", "gain", "increase", "surge", "rally", "boost", "jump"],
        "ä¸‹è·Œ": ["down", "fall", "drop", "decline", "plunge", "crash", "slide"],
        "ä¸šç»©": ["earnings", "revenue", "profit", "income", "performance"],
        "æ”¿ç­–": ["policy", "regulation", "government", "federal", "law"],
    }
    
    found_keywords = []
    for category, words in keyword_categories.items():
        for word in words:
            if word in text_lower:
                found_keywords.append(category)
                break
    
    return found_keywords[:5]

def analyze_universal_sentiment(keywords, title, summary):
    """é€šç”¨æƒ…ç»ªåˆ†æ"""
    text = (title + ' ' + summary).lower()
    
    # ç§¯æè¯æ±‡
    positive_words = ["beat", "exceed", "outperform", "growth", "increase", "rise", "gain", 
                     "strong", "robust", "solid", "success", "win", "breakthrough", "innovation"]
    
    # æ¶ˆæè¯æ±‡
    negative_words = ["miss", "decline", "fall", "drop", "weak", "poor", "loss", "fail",
                     "concern", "worry", "risk", "problem", "issue", "challenge"]
    
    positive_count = sum(1 for word in positive_words if word in text)
    negative_count = sum(1 for word in negative_words if word in text)
    
    # ç»“åˆå…³é”®è¯åˆ¤æ–­
    bullish_keywords = ["ä¸Šæ¶¨", "ä¸šç»©", "ç§‘æŠ€"]
    bearish_keywords = ["ä¸‹è·Œ", "æ”¿ç­–"]
    
    keyword_bullish = sum(1 for kw in keywords if kw in bullish_keywords)
    keyword_bearish = sum(1 for kw in keywords if kw in bearish_keywords)
    
    total_bullish = positive_count + keyword_bullish
    total_bearish = negative_count + keyword_bearish
    
    if total_bullish > total_bearish:
        return "åˆ©å¥½"
    elif total_bearish > total_bullish:
        return "åˆ©ç©º"
    else:
        return "ä¸­æ€§"

# ==================== å¤šæºæ–°é—»è·å–ç³»ç»Ÿ ====================

def fetch_yfinance_news(ticker):
    """æ–¹æ³•1: ä½¿ç”¨ yfinance è·å–æ–°é—»"""
    news_items = []
    try:
        stock = yf.Ticker(ticker)
        news = stock.news
        
        if news and len(news) > 0:
            for i, article in enumerate(news[:5]):
                try:
                    # å¼ºå¥çš„æ•°æ®æå–
                    title = ""
                    summary = ""
                    link = ""
                    source = "Yahoo Finance"
                    pub_time = datetime.now() - timedelta(hours=i+1)
                    
                    if isinstance(article, dict):
                        # å¤šç§æ–¹å¼æå–æ ‡é¢˜
                        title = (article.get('title') or 
                               article.get('headline') or 
                               article.get('shortName') or
                               article.get('longName', ''))
                        
                        # å¤šç§æ–¹å¼æå–æ‘˜è¦
                        summary = (article.get('summary') or 
                                 article.get('description') or 
                                 article.get('snippet') or
                                 article.get('content', ''))
                        
                        # æå–é“¾æ¥
                        if 'link' in article:
                            link = article['link']
                        elif 'url' in article:
                            link = article['url']
                        elif 'clickThroughUrl' in article and isinstance(article['clickThroughUrl'], dict):
                            link = article['clickThroughUrl'].get('url', '')
                        
                        # æå–æ¥æº
                        if 'provider' in article and isinstance(article['provider'], dict):
                            source = article['provider'].get('displayName', 'Yahoo Finance')
                        elif 'source' in article:
                            source = article['source']
                        
                        # æå–æ—¶é—´
                        if 'providerPublishTime' in article:
                            try:
                                pub_time = datetime.fromtimestamp(article['providerPublishTime'])
                            except:
                                pass
                    
                    # éªŒè¯å¿…è¦å­—æ®µ
                    if title and len(title.strip()) > 10:
                        news_items.append({
                            'title': title.strip(),
                            'summary': summary.strip() if summary else 'æš‚æ— æ‘˜è¦',
                            'link': link,
                            'source': source,
                            'published': pub_time,
                            'method': 'yfinance'
                        })
                
                except Exception as e:
                    continue
    
    except Exception as e:
        pass
    
    return news_items

def fetch_fallback_news(ticker):
    """æ–¹æ³•2: å¤‡é€‰æ–°é—»è·å–ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    # è¿™é‡Œå¯ä»¥æ¥å…¥å…¶ä»–æ–°é—»APIï¼Œæ¯”å¦‚Alpha Vantage, Polygonç­‰
    # æš‚æ—¶è¿”å›ç©ºåˆ—è¡¨
    return []

def get_comprehensive_news(ticker):
    """ç»¼åˆæ–°é—»è·å– - å¤šæºåˆå¹¶"""
    all_news = []
    
    # æ–¹æ³•1: yfinance
    yf_news = fetch_yfinance_news(ticker)
    all_news.extend(yf_news)
    
    # æ–¹æ³•2: å¤‡é€‰æ–¹æ¡ˆ
    if len(all_news) < 3:
        fallback_news = fetch_fallback_news(ticker)
        all_news.extend(fallback_news)
    
    # å¦‚æœä»ç„¶æ²¡æœ‰æ–°é—»ï¼Œå°è¯•è·å–å¸‚åœºç»¼åˆæ–°é—»
    if len(all_news) < 3:
        market_news = fetch_yfinance_news("^GSPC")  # S&P 500
        all_news.extend(market_news)
    
    return all_news

@st.cache_data(ttl=1800)
def fetch_universal_financial_news(ticker=None, debug=False):
    """é€šç”¨è´¢ç»æ–°é—»è·å–ç³»ç»Ÿ"""
    current_time = datetime.now()
    
    if debug:
        st.sidebar.write(f"ğŸ” å¼€å§‹è·å– {ticker or 'å¸‚åœº'} æ–°é—»...")
    
    try:
        # è·å–æ–°é—»
        raw_news = get_comprehensive_news(ticker) if ticker else get_comprehensive_news("^GSPC")
        
        if debug:
            st.sidebar.write(f"ğŸ“° åŸå§‹æ–°é—»æ•°é‡: {len(raw_news)}")
        
        processed_news = []
        
        for i, news_item in enumerate(raw_news):
            try:
                # ç¿»è¯‘å¤„ç†
                translated_title = smart_universal_translate(news_item['title'])
                translated_summary = smart_universal_translate(news_item['summary'])
                
                # å…³é”®è¯æå–
                keywords = extract_universal_keywords(news_item['title'] + ' ' + news_item['summary'])
                
                # æƒ…ç»ªåˆ†æ
                sentiment = analyze_universal_sentiment(keywords, news_item['title'], news_item['summary'])
                
                processed_item = {
                    "title": translated_title,
                    "summary": translated_summary[:300] + '...' if len(translated_summary) > 300 else translated_summary,
                    "published": news_item['published'],
                    "url": news_item['link'],
                    "source": news_item['source'],
                    "category": "real_news",
                    "keywords": keywords,
                    "sentiment": sentiment,
                    "is_real": True,
                    "ticker": ticker or "MARKET",
                    "method": news_item.get('method', 'unknown')
                }
                
                processed_news.append(processed_item)
                
            except Exception as e:
                if debug:
                    st.sidebar.error(f"å¤„ç†æ–°é—» {i+1} å¤±è´¥: {str(e)}")
                continue
        
        # æŒ‰æ—¶é—´æ’åº
        processed_news.sort(key=lambda x: x['published'], reverse=True)
        
        if debug:
            st.sidebar.success(f"âœ… æˆåŠŸå¤„ç† {len(processed_news)} æ¡æ–°é—»")
        
        # å¦‚æœæ²¡æœ‰æ–°é—»ï¼Œè¿”å›æç¤º
        if len(processed_news) == 0:
            return [{
                "title": f"æš‚æ—  {ticker or 'å¸‚åœº'} ç›¸å…³æ–°é—»",
                "summary": "å½“å‰æ—¶æ®µæš‚æ— ç›¸å…³æ–°é—»æ›´æ–°ã€‚å»ºè®®ç¨åé‡è¯•æˆ–å°è¯•å…¶ä»–è‚¡ç¥¨ä»£ç ã€‚ä¹Ÿå¯èƒ½æ˜¯APIè®¿é—®é™åˆ¶å¯¼è‡´ï¼Œå»ºè®®ä½¿ç”¨VPNæˆ–ç¨åé‡è¯•ã€‚",
                "published": current_time,
                "url": "https://finance.yahoo.com",
                "source": "ç³»ç»Ÿæç¤º",
                "category": "system_info",
                "keywords": ["ç³»ç»Ÿ"],
                "sentiment": "ä¸­æ€§",
                "is_real": False,
                "ticker": ticker or "MARKET"
            }]
        
        return processed_news
        
    except Exception as e:
        error_msg = f"æ–°é—»è·å–ç³»ç»Ÿé”™è¯¯: {str(e)}"
        if debug:
            st.sidebar.error(error_msg)
        
        return [{
            "title": "æ–°é—»è·å–æœåŠ¡å¼‚å¸¸",
            "summary": f"ç³»ç»Ÿé‡åˆ°æŠ€æœ¯é—®é¢˜: {error_msg}ã€‚è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•ã€‚",
            "published": current_time,
            "url": "",
            "source": "ç³»ç»Ÿé”™è¯¯",
            "category": "system_error",
            "keywords": ["é”™è¯¯"],
            "sentiment": "ä¸­æ€§",
            "is_real": False,
            "ticker": ticker or "MARKET"
        }]

def get_sentiment_advice(sentiment):
    """æ ¹æ®æƒ…ç»ªç»™å‡ºæŠ•èµ„å»ºè®®"""
    if sentiment == "åˆ©å¥½":
        return {
            "icon": "ğŸ“ˆ",
            "advice": "ç§¯æä¿¡å·ï¼Œå…³æ³¨æŠ•èµ„æœºä¼š",
            "action": "å¯è€ƒè™‘é€‚å½“å¢åŠ ä»“ä½ï¼Œå…³æ³¨ç›¸å…³æ¿å—",
            "color": "green"
        }
    elif sentiment == "åˆ©ç©º":
        return {
            "icon": "ğŸ“‰",
            "advice": "é£é™©ä¿¡å·ï¼Œå»ºè®®è°¨æ…",
            "action": "æ§åˆ¶é£é™©æ•å£ï¼Œå…³æ³¨é˜²å¾¡æ€§èµ„äº§",
            "color": "red"
        }
    else:
        return {
            "icon": "ğŸ“Š",
            "advice": "ä¸­æ€§ä¿¡å·ï¼Œç»´æŒç­–ç•¥",
            "action": "ä¿æŒè§‚å¯Ÿï¼Œç­‰å¾…æ›´æ˜ç¡®ä¿¡å·",
            "color": "gray"
        }

# ==================== ä¾§è¾¹æ è®¾ç½® ====================
with st.sidebar:
    st.header("ğŸ“° æ–°é—»è®¾ç½®")
    
    # è‚¡ç¥¨ä»£ç è¾“å…¥
    ticker_input = st.text_input(
        "è¾“å…¥ç¾è‚¡ä»£ç :",
        placeholder="ä¾‹å¦‚: AAPL, TSLA, GOOGL, NVDA...",
        help="æ”¯æŒæ‰€æœ‰ç¾è‚¡ä»£ç ï¼Œç•™ç©ºè·å–å¸‚åœºç»¼åˆæ–°é—»"
    ).upper().strip()
    
    # å¿«é€Ÿé€‰æ‹©
    st.markdown("#### ğŸ“ˆ çƒ­é—¨è‚¡ç¥¨å¿«é€‰")
    quick_picks = {
        "å¸‚åœºç»¼åˆ": "",
        "è‹¹æœ AAPL": "AAPL",
        "ç‰¹æ–¯æ‹‰ TSLA": "TSLA", 
        "å¾®è½¯ MSFT": "MSFT",
        "è‹±ä¼Ÿè¾¾ NVDA": "NVDA",
        "äºšé©¬é€Š AMZN": "AMZN",
        "è°·æ­Œ GOOGL": "GOOGL",
        "Meta META": "META"
    }
    
    selected_quick = st.selectbox("æˆ–é€‰æ‹©çƒ­é—¨è‚¡ç¥¨:", list(quick_picks.keys()))
    
    # ç¡®å®šæœ€ç»ˆçš„ticker
    final_ticker = ticker_input if ticker_input else quick_picks[selected_quick]
    
    st.markdown("---")
    
    # é«˜çº§é€‰é¡¹
    st.markdown("#### âš™ï¸ é«˜çº§é€‰é¡¹")
    debug_mode = st.checkbox("ğŸ”§ è°ƒè¯•æ¨¡å¼", help="æ˜¾ç¤ºè¯¦ç»†çš„è·å–è¿‡ç¨‹")
    show_method = st.checkbox("ğŸ“¡ æ˜¾ç¤ºæ•°æ®æº", help="æ˜¾ç¤ºæ–°é—»æ¥æºæ–¹æ³•")
    
    # è·å–æ–°é—»æŒ‰é’®
    st.markdown("#### ğŸš€ æ“ä½œ")
    if st.button("ğŸ“° è·å–æœ€æ–°æ–°é—»", type="primary", use_container_width=True):
        st.session_state.selected_ticker = final_ticker
        with st.spinner(f"æ­£åœ¨è·å– {final_ticker or 'å¸‚åœº'} æœ€æ–°æ–°é—»..."):
            news_data = fetch_universal_financial_news(final_ticker, debug=debug_mode)
            st.session_state.news_data = news_data
    
    if st.button("ğŸ”„ åˆ·æ–°ç¼“å­˜", use_container_width=True):
        fetch_universal_financial_news.clear()
        st.session_state.news_data = None
        st.success("ç¼“å­˜å·²æ¸…é™¤ï¼")
        st.rerun()
    
    st.markdown("---")
    
    # ä½¿ç”¨è¯´æ˜
    with st.expander("ğŸ“– ä½¿ç”¨è¯´æ˜"):
        st.markdown("""
        ### ğŸ¯ åŠŸèƒ½ç‰¹è‰²
        - **é€šç”¨æ”¯æŒ**: æ”¯æŒæ‰€æœ‰ç¾è‚¡ä»£ç 
        - **å¤šæºè·å–**: å¤šä¸ªæ•°æ®æºä¿è¯å¯é æ€§  
        - **æ™ºèƒ½ç¿»è¯‘**: é€šç”¨è´¢ç»æœ¯è¯­ç¿»è¯‘
        - **æƒ…ç»ªåˆ†æ**: AIé©±åŠ¨çš„æƒ…ç»ªåˆ¤æ–­
        - **å®æ—¶æ›´æ–°**: 30åˆ†é’Ÿç¼“å­˜æœºåˆ¶
        
        ### ğŸ“ ä½¿ç”¨æ–¹æ³•
        1. è¾“å…¥ä»»æ„ç¾è‚¡ä»£ç æˆ–é€‰æ‹©çƒ­é—¨è‚¡ç¥¨
        2. ç‚¹å‡»"è·å–æœ€æ–°æ–°é—»"
        3. æŸ¥çœ‹ç¿»è¯‘åçš„æ–°é—»å’Œåˆ†æç»“æœ
        4. æ ¹æ®æƒ…ç»ªå»ºè®®è°ƒæ•´æŠ•èµ„ç­–ç•¥
        
        ### ğŸ’¡ å°è´´å£«
        - ç•™ç©ºä»£ç è·å–å¸‚åœºç»¼åˆæ–°é—»
        - å¼€å¯è°ƒè¯•æ¨¡å¼æŸ¥çœ‹è¯¦ç»†è¿‡ç¨‹
        - é‡åˆ°é—®é¢˜å¯å°è¯•åˆ·æ–°ç¼“å­˜
        """)

# ==================== ä¸»ç•Œé¢ ====================
if st.session_state.news_data is not None:
    news_data = st.session_state.news_data
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_news = len(news_data)
    real_news = len([n for n in news_data if n.get('is_real', False)])
    bullish_count = len([n for n in news_data if n['sentiment'] == 'åˆ©å¥½'])
    bearish_count = len([n for n in news_data if n['sentiment'] == 'åˆ©ç©º'])
    neutral_count = len([n for n in news_data if n['sentiment'] == 'ä¸­æ€§'])
    
    # æ˜¾ç¤ºç»Ÿè®¡é¢æ¿
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.metric("ğŸ“° æ–°é—»æ€»æ•°", total_news)
    with col2:
        st.metric("âœ… çœŸå®æ–°é—»", real_news)
    with col3:
        st.metric("ğŸ“ˆ åˆ©å¥½", bullish_count, delta=f"{bullish_count/total_news*100:.0f}%" if total_news > 0 else "0%")
    with col4:
        st.metric("ğŸ“‰ åˆ©ç©º", bearish_count, delta=f"{bearish_count/total_news*100:.0f}%" if total_news > 0 else "0%")
    with col5:
        st.metric("ğŸ“Š ä¸­æ€§", neutral_count, delta=f"{neutral_count/total_news*100:.0f}%" if total_news > 0 else "0%")
    
    # å¸‚åœºæƒ…ç»ªæ€»ç»“
    if real_news > 0:
        if bullish_count > bearish_count:
            st.success("ğŸ“ˆ æ•´ä½“å¸‚åœºæƒ…ç»ª: åå‘ä¹è§‚")
        elif bearish_count > bullish_count:
            st.error("ğŸ“‰ æ•´ä½“å¸‚åœºæƒ…ç»ª: åå‘è°¨æ…")
        else:
            st.info("ğŸ“Š æ•´ä½“å¸‚åœºæƒ…ç»ª: ç›¸å¯¹å¹³è¡¡")
    
    st.markdown("---")
    
    # æ˜¾ç¤ºæ–°é—»åˆ—è¡¨
    if real_news > 0:
        st.subheader(f"ğŸ“° {st.session_state.selected_ticker or 'å¸‚åœº'} æœ€æ–°æ–°é—»")
        
        for i, news in enumerate(news_data):
            if news.get('is_real', False):
                sentiment_info = get_sentiment_advice(news['sentiment'])
                
                with st.container():
                    col_main, col_side = st.columns([3, 1])
                    
                    with col_main:
                        # æ ‡é¢˜å’ŒåŸºæœ¬ä¿¡æ¯
                        st.markdown(f"### ğŸ“° {news['title']}")
                        
                        time_str = news['published'].strftime('%Y-%m-%d %H:%M')
                        source_info = f"ğŸ•’ {time_str} | ğŸ“¡ {news['source']}"
                        
                        if show_method and 'method' in news:
                            source_info += f" | ğŸ”§ {news['method']}"
                        
                        st.caption(source_info)
                        
                        # æ‘˜è¦
                        st.write(news['summary'])
                        
                        # å…³é”®è¯
                        if news['keywords']:
                            keywords_str = " ".join([f"`{kw}`" for kw in news['keywords']])
                            st.markdown(f"**ğŸ·ï¸ å…³é”®è¯:** {keywords_str}")
                        
                        # é“¾æ¥
                        if news['url']:
                            st.markdown(f"ğŸ”— [é˜…è¯»åŸæ–‡]({news['url']})")
                    
                    with col_side:
                        # æƒ…ç»ªåˆ†æå¡ç‰‡
                        sentiment_color = sentiment_info['color']
                        st.markdown(f"### {sentiment_info['icon']}")
                        st.markdown(f"**<span style='color:{sentiment_color}'>{news['sentiment']}</span>**", unsafe_allow_html=True)
                        
                        st.write("**ğŸ“‹ å¸‚åœºå½±å“:**")
                        st.write(sentiment_info['advice'])
                        
                        st.write("**ğŸ’¡ æ“ä½œå»ºè®®:**")
                        st.write(sentiment_info['action'])
                
                st.markdown("---")
    
    else:
        st.warning("ğŸ“­ å½“å‰æ²¡æœ‰è·å–åˆ°çœŸå®æ–°é—»ï¼Œå»ºè®®æ£€æŸ¥è‚¡ç¥¨ä»£ç æˆ–ç¨åé‡è¯•")

else:
    # æ¬¢è¿é¡µé¢
    st.markdown("""
    ## ğŸ¯ é€šç”¨ç¾è‚¡æ–°é—»åˆ†æç³»ç»Ÿ
    
    ### âœ¨ æ ¸å¿ƒç‰¹è‰²
    
    #### ğŸ“ˆ é€šç”¨æ”¯æŒ
    - ğŸ” æ”¯æŒ**æ‰€æœ‰ç¾è‚¡è‚¡ç¥¨ä»£ç **
    - ğŸŒ æ— éœ€ç¡¬ç¼–ç ç‰¹å®šå…¬å¸
    - ğŸ“Š è‡ªåŠ¨é€‚åº”ä¸åŒè¡Œä¸šå’Œå…¬å¸
    
    #### ğŸ›¡ï¸ å¤šé‡ä¿éšœ
    - ğŸ“¡ å¤šæ•°æ®æºè·å–ï¼Œæé«˜æˆåŠŸç‡
    - ğŸ”„ æ™ºèƒ½ç¼“å­˜ï¼Œæå‡å“åº”é€Ÿåº¦
    - ğŸš¨ å®Œå–„çš„é”™è¯¯å¤„ç†å’Œé™çº§æ–¹æ¡ˆ
    
    #### ğŸ¤– æ™ºèƒ½åˆ†æ
    - ğŸŒ é€šç”¨è´¢ç»æœ¯è¯­ç¿»è¯‘ç³»ç»Ÿ
    - ğŸ¯ å…³é”®è¯è‡ªåŠ¨æå–
    - ğŸ“Š AIé©±åŠ¨çš„æƒ…ç»ªåˆ†æ
    - ğŸ’¡ ä¸ªæ€§åŒ–æŠ•èµ„å»ºè®®
    
    ### ğŸš€ å¿«é€Ÿå¼€å§‹
    
    1. **è¾“å…¥è‚¡ç¥¨ä»£ç ** - åœ¨å·¦ä¾§è¾“å…¥ä»»æ„ç¾è‚¡ä»£ç ï¼ˆå¦‚ AAPL, TSLA ç­‰ï¼‰
    2. **è·å–æ–°é—»** - ç‚¹å‡»"è·å–æœ€æ–°æ–°é—»"æŒ‰é’®  
    3. **æŸ¥çœ‹åˆ†æ** - æµè§ˆç¿»è¯‘åçš„æ–°é—»å’ŒAIåˆ†æç»“æœ
    4. **æŠ•èµ„å†³ç­–** - æ ¹æ®æƒ…ç»ªåˆ†æå’Œå»ºè®®åˆ¶å®šç­–ç•¥
    
    ### ğŸ’¡ æ”¯æŒç¤ºä¾‹
    
    - **ç§‘æŠ€è‚¡**: AAPL, MSFT, GOOGL, NVDA, META
    - **ç”µåŠ¨è½¦**: TSLA, NIO, XPEV, LI  
    - **é‡‘è**: JPM, BAC, GS, MS
    - **æ¶ˆè´¹**: AMZN, WMT, TGT, COST
    - **åŒ»ç–—**: JNJ, PFE, MRNA, UNH
    
    ---
    
    **ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾“å…¥è‚¡ç¥¨ä»£ç å¼€å§‹ä½¿ç”¨**
    
    **âš ï¸ å…è´£å£°æ˜**: æœ¬ç³»ç»Ÿä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚
    """)
    
    # ç¤ºä¾‹å±•ç¤º
    with st.expander("ğŸ¬ åŠŸèƒ½æ¼”ç¤º"):
        st.markdown("""
        ### ğŸ“Š æ™ºèƒ½ç¿»è¯‘ç¤ºä¾‹
        
        **åŸæ–‡:**
        > "Apple announced that its Q4 revenue increased by 8% year-over-year, beating Wall Street expectations despite supply chain challenges."
        
        **æ™ºèƒ½ç¿»è¯‘:**
        > "è‹¹æœå®£å¸ƒå…¶ç¬¬å››å­£åº¦è¥æ”¶åŒæ¯”å¢é•¿8%ï¼Œå°½ç®¡é¢ä¸´ä¾›åº”é“¾æŒ‘æˆ˜ï¼Œä»è¶…é¢„æœŸã€‚"
        
        **å…³é”®è¯:** `ç§‘æŠ€` `ä¸šç»©` `ä¸Šæ¶¨`
        
        **æƒ…ç»ª:** ğŸ“ˆ åˆ©å¥½
        
        **å»ºè®®:** å¯è€ƒè™‘é€‚å½“å¢åŠ ä»“ä½ï¼Œå…³æ³¨ç›¸å…³æ¿å—
        
        ---
        
        ### ğŸ” é€šç”¨é€‚åº”æ€§
        
        æœ¬ç³»ç»Ÿå¯ä»¥å¤„ç†ä»»ä½•ç¾è‚¡å…¬å¸çš„æ–°é—»ï¼Œæ— è®ºæ˜¯ï¼š
        - å¤§å‹ç§‘æŠ€å…¬å¸ (FAANG)
        - æ–°å…´æˆé•¿è‚¡
        - ä¼ ç»Ÿåˆ¶é€ ä¸š
        - é‡‘èæœåŠ¡ä¸š
        - ç”Ÿç‰©åŒ»è¯è‚¡
        
        æ‰€æœ‰ç¿»è¯‘å’Œåˆ†æéƒ½æ˜¯åŠ¨æ€ç”Ÿæˆçš„ï¼Œä¸ä¾èµ–é¢„è®¾çš„å…¬å¸åˆ—è¡¨ã€‚
        """)

# é¡µè„šä¿¡æ¯
st.markdown("---")
st.markdown("ğŸ“° é€šç”¨ç¾è‚¡æ–°é—»åˆ†æç³»ç»Ÿ | ğŸ”„ å®æ—¶è·å– | ğŸŒ æ™ºèƒ½ç¿»è¯‘ | ğŸ“Š æƒ…ç»ªåˆ†æ | ğŸ’¡ æŠ•èµ„å»ºè®®")
