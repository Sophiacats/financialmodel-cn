import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
import re
import requests
import time
import json
warnings.filterwarnings('ignore')

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ğŸ“° çœŸå®æ–°é—»è·å–ç³»ç»Ÿ",
    page_icon="ğŸ“°",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ– session state
if 'selected_ticker' not in st.session_state:
    st.session_state.selected_ticker = None
if 'news_data' not in st.session_state:
    st.session_state.news_data = None
if 'debug_info' not in st.session_state:
    st.session_state.debug_info = []

st.title("ğŸ“° çœŸå®æ–°é—»è·å–ç³»ç»Ÿ")
st.markdown("**åªè·å–çœŸå®æ–°é—» - æ”¯æŒæ‰€æœ‰ç¾è‚¡ä»£ç  - æ— æ¨¡æ‹Ÿæ•°æ®**")
st.markdown("---")

# ==================== çœŸå®æ–°é—»è·å–å‡½æ•° ====================

def debug_yfinance_detailed(ticker):
    """è¯¦ç»†è°ƒè¯• yfinance"""
    debug_results = []
    
    try:
        debug_results.append(f"ğŸ” å¼€å§‹æµ‹è¯• {ticker}")
        
        # æ­¥éª¤1: åˆ›å»ºtickerå¯¹è±¡
        stock = yf.Ticker(ticker)
        debug_results.append("âœ… æˆåŠŸåˆ›å»º yfinance Ticker å¯¹è±¡")
        
        # æ­¥éª¤2: æµ‹è¯•åŸºæœ¬ä¿¡æ¯
        try:
            info = stock.info
            if info and isinstance(info, dict):
                company_name = info.get('longName', 'N/A')
                debug_results.append(f"âœ… åŸºæœ¬ä¿¡æ¯è·å–æˆåŠŸ: {company_name}")
                debug_results.append(f"ğŸ“Š ä¿¡æ¯å­—æ®µæ•°: {len(info)}")
            else:
                debug_results.append("âŒ åŸºæœ¬ä¿¡æ¯è·å–å¤±è´¥æˆ–ä¸ºç©º")
        except Exception as e:
            debug_results.append(f"âŒ åŸºæœ¬ä¿¡æ¯è·å–å¼‚å¸¸: {str(e)}")
        
        # æ­¥éª¤3: æµ‹è¯•æ–°é—»è·å–
        try:
            news = stock.news
            debug_results.append(f"ğŸ“° æ–°é—»å¯¹è±¡ç±»å‹: {type(news)}")
            
            if news is None:
                debug_results.append("âŒ æ–°é—»å¯¹è±¡ä¸º None")
                return debug_results, []
            
            if hasattr(news, '__len__'):
                news_count = len(news)
                debug_results.append(f"ğŸ“Š æ–°é—»æ•°é‡: {news_count}")
                
                if news_count == 0:
                    debug_results.append("âŒ æ–°é—»åˆ—è¡¨ä¸ºç©º")
                    return debug_results, []
                
                # æ£€æŸ¥ç¬¬ä¸€æ¡æ–°é—»
                first_news = news[0]
                debug_results.append(f"ğŸ“° ç¬¬ä¸€æ¡æ–°é—»ç±»å‹: {type(first_news)}")
                
                if isinstance(first_news, dict):
                    keys = list(first_news.keys())
                    debug_results.append(f"ğŸ”‘ æ–°é—»å­—æ®µ: {keys}")
                    
                    # æ£€æŸ¥å…³é”®å­—æ®µ
                    title = first_news.get('title', '')
                    summary = first_news.get('summary', '')
                    
                    debug_results.append(f"ğŸ“ æ ‡é¢˜é•¿åº¦: {len(title) if title else 0}")
                    debug_results.append(f"ğŸ“„ æ‘˜è¦é•¿åº¦: {len(summary) if summary else 0}")
                    
                    if title:
                        debug_results.append(f"ğŸ“° æ ‡é¢˜é¢„è§ˆ: {title[:100]}...")
                    
                    return debug_results, news
                else:
                    debug_results.append(f"âŒ æ–°é—»æ ¼å¼å¼‚å¸¸: {first_news}")
                    return debug_results, []
            else:
                debug_results.append("âŒ æ–°é—»å¯¹è±¡æ²¡æœ‰é•¿åº¦å±æ€§")
                return debug_results, []
                
        except Exception as e:
            debug_results.append(f"âŒ æ–°é—»è·å–å¼‚å¸¸: {str(e)}")
            return debug_results, []
            
    except Exception as e:
        debug_results.append(f"âŒ æ•´ä½“æµ‹è¯•å¤±è´¥: {str(e)}")
        return debug_results, []

def fetch_real_yfinance_news(ticker, debug_mode=False):
    """è·å–çœŸå®çš„ yfinance æ–°é—»"""
    if debug_mode:
        debug_info, raw_news = debug_yfinance_detailed(ticker)
        st.session_state.debug_info = debug_info
        
        # åœ¨ä¾§è¾¹æ æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
        with st.sidebar:
            st.subheader("ğŸ” è°ƒè¯•ä¿¡æ¯")
            for info in debug_info:
                if "âœ…" in info:
                    st.success(info)
                elif "âŒ" in info:
                    st.error(info)
                elif "âš ï¸" in info:
                    st.warning(info)
                else:
                    st.info(info)
    else:
        try:
            stock = yf.Ticker(ticker)
            raw_news = stock.news
        except Exception as e:
            st.error(f"yfinance è·å–å¤±è´¥: {str(e)}")
            return []
    
    if not raw_news or len(raw_news) == 0:
        return []
    
    processed_news = []
    
    for i, article in enumerate(raw_news):
        try:
            if not isinstance(article, dict):
                continue
            
            # æå–åŸºæœ¬ä¿¡æ¯
            title = article.get('title', '')
            summary = article.get('summary', '') or article.get('description', '')
            
            # è·³è¿‡æ²¡æœ‰æ ‡é¢˜çš„æ–°é—»
            if not title or len(title.strip()) < 10:
                continue
            
            # æå–URL
            url = ''
            if 'link' in article:
                url = article['link']
            elif 'url' in article:
                url = article['url']
            elif 'clickThroughUrl' in article and isinstance(article['clickThroughUrl'], dict):
                url = article['clickThroughUrl'].get('url', '')
            
            # æå–æ¥æº
            source = 'Yahoo Finance'
            if 'provider' in article and isinstance(article['provider'], dict):
                source = article['provider'].get('displayName', 'Yahoo Finance')
            elif 'source' in article:
                source = str(article['source'])
            
            # æå–æ—¶é—´
            published_time = datetime.now() - timedelta(hours=i+1)
            if 'providerPublishTime' in article:
                try:
                    published_time = datetime.fromtimestamp(article['providerPublishTime'])
                except:
                    pass
            elif 'publishedAt' in article:
                try:
                    published_time = datetime.fromisoformat(article['publishedAt'].replace('Z', '+00:00')).replace(tzinfo=None)
                except:
                    pass
            
            processed_news.append({
                'title': title.strip(),
                'summary': summary.strip() if summary else 'æš‚æ— æ‘˜è¦',
                'url': url,
                'source': source,
                'published': published_time,
                'is_real': True,
                'raw_data': article  # ä¿ç•™åŸå§‹æ•°æ®ç”¨äºè°ƒè¯•
            })
            
        except Exception as e:
            if debug_mode:
                st.error(f"å¤„ç†ç¬¬ {i+1} æ¡æ–°é—»æ—¶å‡ºé”™: {str(e)}")
            continue
    
    return processed_news

def try_alternative_news_sources(ticker):
    """å°è¯•å…¶ä»–çœŸå®æ–°é—»æº"""
    # è¿™é‡Œå¯ä»¥æ·»åŠ å…¶ä»–çœŸå®çš„æ–°é—»API
    # ä¾‹å¦‚: Alpha Vantage, Polygon.io, NewsAPIç­‰
    # å½“å‰è¿”å›ç©ºåˆ—è¡¨ï¼Œç­‰å¾…é›†æˆçœŸå®API
    return []

@st.cache_data(ttl=1800)
def get_real_financial_news(ticker, debug_mode=False):
    """è·å–çœŸå®è´¢ç»æ–°é—»çš„ä¸»å‡½æ•°"""
    all_news = []
    
    # æ–¹æ³•1: yfinance
    yf_news = fetch_real_yfinance_news(ticker, debug_mode)
    if yf_news:
        all_news.extend(yf_news)
        if debug_mode:
            st.sidebar.success(f"âœ… yfinance: æˆåŠŸè·å– {len(yf_news)} æ¡çœŸå®æ–°é—»")
    else:
        if debug_mode:
            st.sidebar.warning("âš ï¸ yfinance: æœªè·å–åˆ°æ–°é—»æ•°æ®")
    
    # æ–¹æ³•2: å…¶ä»–çœŸå®æ–°é—»æº
    alt_news = try_alternative_news_sources(ticker)
    if alt_news:
        all_news.extend(alt_news)
        if debug_mode:
            st.sidebar.success(f"âœ… å¤‡é€‰æº: æˆåŠŸè·å– {len(alt_news)} æ¡çœŸå®æ–°é—»")
    
    # æŒ‰æ—¶é—´æ’åº
    if all_news:
        all_news.sort(key=lambda x: x['published'], reverse=True)
    
    return all_news

# ==================== ç¿»è¯‘å’Œåˆ†æç³»ç»Ÿï¼ˆä»…å¤„ç†çœŸå®æ–°é—»ï¼‰====================

def create_financial_translation_dict():
    """åˆ›å»ºè´¢ç»æœ¯è¯­ç¿»è¯‘è¯å…¸"""
    return {
        # åŸºç¡€è´¢ç»æœ¯è¯­
        'earnings': 'è´¢æŠ¥', 'revenue': 'è¥æ”¶', 'profit': 'åˆ©æ¶¦', 'loss': 'äºæŸ',
        'dividend': 'åˆ†çº¢', 'shares': 'è‚¡ä»½', 'stock': 'è‚¡ç¥¨', 'market': 'å¸‚åœº',
        'investor': 'æŠ•èµ„è€…', 'shareholder': 'è‚¡ä¸œ', 'trading': 'äº¤æ˜“',
        
        # å…¬å¸è¡Œä¸º
        'announced': 'å®£å¸ƒ', 'reported': 'æŠ¥å‘Š', 'disclosed': 'æŠ«éœ²', 'revealed': 'é€éœ²',
        'acquired': 'æ”¶è´­', 'merged': 'åˆå¹¶', 'launched': 'æ¨å‡º', 'released': 'å‘å¸ƒ',
        
        # å¸‚åœºè¡¨ç°
        'increased': 'å¢é•¿', 'decreased': 'ä¸‹é™', 'rose': 'ä¸Šæ¶¨', 'fell': 'ä¸‹è·Œ',
        'gained': 'ä¸Šæ¶¨', 'dropped': 'ä¸‹è·Œ', 'surged': 'é£™å‡', 'plunged': 'æš´è·Œ',
        
        # ä¸šç»©ç›¸å…³
        'beat expectations': 'è¶…é¢„æœŸ', 'missed expectations': 'ä¸åŠé¢„æœŸ',
        'exceeded estimates': 'è¶…è¿‡é¢„æœŸ', 'fell short': 'æœªè¾¾é¢„æœŸ',
        'year-over-year': 'åŒæ¯”', 'quarter-over-quarter': 'ç¯æ¯”',
        
        # è¡Œä¸šé€šç”¨
        'technology': 'ç§‘æŠ€', 'healthcare': 'åŒ»ç–—', 'financial': 'é‡‘è',
        'energy': 'èƒ½æº', 'consumer': 'æ¶ˆè´¹', 'industrial': 'å·¥ä¸š',
        
        # æ•°å€¼ç›¸å…³
        'billion': 'åäº¿', 'million': 'ç™¾ä¸‡', 'percent': 'ç™¾åˆ†æ¯”',
        'quarterly': 'å­£åº¦', 'annual': 'å¹´åº¦', 'monthly': 'æœˆåº¦'
    }

def translate_financial_text(text):
    """ç¿»è¯‘è´¢ç»æ–‡æœ¬"""
    if not text:
        return text
    
    translation_dict = create_financial_translation_dict()
    result = text
    
    # åº”ç”¨è¯æ±‡ç¿»è¯‘
    for en_term, zh_term in translation_dict.items():
        pattern = r'\b' + re.escape(en_term) + r'\b'
        result = re.sub(pattern, zh_term, result, flags=re.IGNORECASE)
    
    # å¤„ç†æ•°å­—è¡¨è¾¾
    result = re.sub(r'\$([0-9,.]+)\s*billion', r'\1åäº¿ç¾å…ƒ', result, flags=re.IGNORECASE)
    result = re.sub(r'\$([0-9,.]+)\s*million', r'\1ç™¾ä¸‡ç¾å…ƒ', result, flags=re.IGNORECASE)
    result = re.sub(r'([0-9,.]+)%', r'\1%', result)
    
    return result

def extract_keywords_from_real_news(title, summary):
    """ä»çœŸå®æ–°é—»ä¸­æå–å…³é”®è¯"""
    text = (title + ' ' + summary).lower()
    
    keyword_patterns = {
        'ä¸šç»©': ['earnings', 'revenue', 'profit', 'income', 'results'],
        'å¹¶è´­': ['acquisition', 'merger', 'acquire', 'buy', 'purchase'],
        'æ–°äº§å“': ['launch', 'introduce', 'unveil', 'release', 'debut'],
        'è´¢åŠ¡': ['financial', 'fiscal', 'budget', 'cash', 'debt'],
        'å¸‚åœº': ['market', 'trading', 'stock', 'share', 'price'],
        'å¢é•¿': ['growth', 'increase', 'rise', 'gain', 'up'],
        'ä¸‹é™': ['decline', 'decrease', 'fall', 'drop', 'down'],
        'ç›‘ç®¡': ['regulatory', 'regulation', 'approval', 'fda', 'government']
    }
    
    found_keywords = []
    for category, patterns in keyword_patterns.items():
        if any(pattern in text for pattern in patterns):
            found_keywords.append(category)
    
    return found_keywords[:5]

def analyze_real_news_sentiment(title, summary, keywords):
    """åˆ†æçœŸå®æ–°é—»çš„æƒ…ç»ª"""
    text = (title + ' ' + summary).lower()
    
    positive_signals = ['beat', 'exceed', 'strong', 'growth', 'increase', 'success', 
                       'approval', 'breakthrough', 'record', 'high', 'gain']
    negative_signals = ['miss', 'weak', 'decline', 'fall', 'concern', 'challenge',
                       'risk', 'loss', 'drop', 'low', 'worry']
    
    pos_count = sum(1 for signal in positive_signals if signal in text)
    neg_count = sum(1 for signal in negative_signals if signal in text)
    
    # ç»“åˆå…³é”®è¯
    bullish_keywords = ['ä¸šç»©', 'å¢é•¿', 'æ–°äº§å“']
    bearish_keywords = ['ä¸‹é™', 'ç›‘ç®¡']
    
    keyword_pos = sum(1 for kw in keywords if kw in bullish_keywords)
    keyword_neg = sum(1 for kw in keywords if kw in bearish_keywords)
    
    total_pos = pos_count + keyword_pos
    total_neg = neg_count + keyword_neg
    
    if total_pos > total_neg:
        return 'åˆ©å¥½'
    elif total_neg > total_pos:
        return 'åˆ©ç©º'
    else:
        return 'ä¸­æ€§'

def get_investment_advice(sentiment):
    """æ ¹æ®æƒ…ç»ªç»™å‡ºæŠ•èµ„å»ºè®®"""
    advice_map = {
        'åˆ©å¥½': {
            'icon': 'ğŸ“ˆ',
            'advice': 'ç§¯æä¿¡å·ï¼Œå¸‚åœºååº”å¯èƒ½æ­£é¢',
            'action': 'å…³æ³¨ä¹°å…¥æœºä¼šï¼Œä½†éœ€ç»“åˆå…¶ä»–å› ç´ ',
            'color': 'green'
        },
        'åˆ©ç©º': {
            'icon': 'ğŸ“‰',
            'advice': 'è°¨æ…ä¿¡å·ï¼Œå¯èƒ½å½±å“è‚¡ä»·',
            'action': 'æ³¨æ„é£é™©æ§åˆ¶ï¼Œè€ƒè™‘å‡ä»“æˆ–è§‚æœ›',
            'color': 'red'
        },
        'ä¸­æ€§': {
            'icon': 'ğŸ“Š',
            'advice': 'ä¸­æ€§ä¿¡å·ï¼Œå½±å“æœ‰é™',
            'action': 'ä¿æŒç°æœ‰ç­–ç•¥ï¼Œç»§ç»­è§‚å¯Ÿ',
            'color': 'gray'
        }
    }
    return advice_map.get(sentiment, advice_map['ä¸­æ€§'])

# ==================== ä¾§è¾¹æ  ====================
with st.sidebar:
    st.header("ğŸ“° çœŸå®æ–°é—»è·å–")
    
    # è‚¡ç¥¨ä»£ç è¾“å…¥
    ticker_input = st.text_input(
        "è¾“å…¥ä»»æ„ç¾è‚¡ä»£ç :",
        placeholder="ä¾‹å¦‚: AAPL, TSLA, AMZN, GOOGL...",
        help="æ”¯æŒæ‰€æœ‰åœ¨ç¾å›½äº¤æ˜“æ‰€ä¸Šå¸‚çš„è‚¡ç¥¨"
    ).upper().strip()
    
    st.markdown("---")
    
    # è°ƒè¯•é€‰é¡¹
    st.subheader("ğŸ”§ è°ƒè¯•é€‰é¡¹")
    debug_mode = st.checkbox("å¯ç”¨è°ƒè¯•æ¨¡å¼", help="æ˜¾ç¤ºè¯¦ç»†çš„æ•°æ®è·å–è¿‡ç¨‹")
    show_raw_data = st.checkbox("æ˜¾ç¤ºåŸå§‹æ•°æ®", help="æ˜¾ç¤ºæ–°é—»çš„åŸå§‹JSONæ•°æ®")
    
    st.markdown("---")
    
    # è·å–æ–°é—»
    if st.button("ğŸ“° è·å–çœŸå®æ–°é—»", type="primary", use_container_width=True):
        if ticker_input:
            st.session_state.selected_ticker = ticker_input
            
            with st.spinner(f"æ­£åœ¨è·å– {ticker_input} çš„çœŸå®æ–°é—»..."):
                real_news = get_real_financial_news(ticker_input, debug_mode)
                
                if real_news:
                    # å¤„ç†çœŸå®æ–°é—»
                    processed_news = []
                    for news in real_news:
                        translated_title = translate_financial_text(news['title'])
                        translated_summary = translate_financial_text(news['summary'])
                        keywords = extract_keywords_from_real_news(news['title'], news['summary'])
                        sentiment = analyze_real_news_sentiment(news['title'], news['summary'], keywords)
                        
                        processed_item = {
                            'title': translated_title,
                            'summary': translated_summary,
                            'published': news['published'],
                            'source': news['source'],
                            'url': news['url'],
                            'keywords': keywords,
                            'sentiment': sentiment,
                            'is_real': True,
                            'raw_data': news.get('raw_data') if show_raw_data else None
                        }
                        processed_news.append(processed_item)
                    
                    st.session_state.news_data = processed_news
                    st.success(f"âœ… æˆåŠŸè·å– {len(processed_news)} æ¡çœŸå®æ–°é—»")
                else:
                    st.session_state.news_data = []
                    st.warning("âš ï¸ æœªèƒ½è·å–åˆ°çœŸå®æ–°é—»æ•°æ®")
        else:
            st.error("è¯·è¾“å…¥è‚¡ç¥¨ä»£ç ")
    
    # æ¸…é™¤ç¼“å­˜
    if st.button("ğŸ”„ æ¸…é™¤ç¼“å­˜", use_container_width=True):
        get_real_financial_news.clear()
        st.session_state.news_data = None
        st.session_state.debug_info = []
        st.success("ç¼“å­˜å·²æ¸…é™¤")
    
    # ç½‘ç»œæµ‹è¯•
    if st.button("ğŸŒ æµ‹è¯•ç½‘ç»œè¿æ¥"):
        with st.spinner("æµ‹è¯•ç½‘ç»œè¿æ¥..."):
            try:
                response = requests.get('https://finance.yahoo.com', timeout=10)
                if response.status_code == 200:
                    st.success("âœ… ç½‘ç»œè¿æ¥æ­£å¸¸")
                else:
                    st.warning(f"âš ï¸ ç½‘ç»œå“åº”: {response.status_code}")
            except Exception as e:
                st.error(f"âŒ ç½‘ç»œè¿æ¥å¤±è´¥: {str(e)}")

# ==================== ä¸»ç•Œé¢ ====================
if st.session_state.news_data is not None:
    news_data = st.session_state.news_data
    ticker = st.session_state.selected_ticker
    
    if len(news_data) > 0:
        # ç»Ÿè®¡ä¿¡æ¯
        total = len(news_data)
        bullish = len([n for n in news_data if n['sentiment'] == 'åˆ©å¥½'])
        bearish = len([n for n in news_data if n['sentiment'] == 'åˆ©ç©º'])
        neutral = len([n for n in news_data if n['sentiment'] == 'ä¸­æ€§'])
        
        # æ˜¾ç¤ºç»Ÿè®¡
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ“° çœŸå®æ–°é—»", total)
        with col2:
            st.metric("ğŸ“ˆ åˆ©å¥½", bullish)
        with col3:
            st.metric("ğŸ“‰ åˆ©ç©º", bearish)
        with col4:
            st.metric("ğŸ“Š ä¸­æ€§", neutral)
        
        # æƒ…ç»ªæ€»ç»“
        if bullish > bearish:
            st.success(f"ğŸ“ˆ {ticker} æ–°é—»æƒ…ç»ªåå‘ç§¯æ")
        elif bearish > bullish:
            st.error(f"ğŸ“‰ {ticker} æ–°é—»æƒ…ç»ªåå‘æ¶ˆæ")
        else:
            st.info(f"ğŸ“Š {ticker} æ–°é—»æƒ…ç»ªç›¸å¯¹å¹³è¡¡")
        
        st.markdown("---")
        
        # æ˜¾ç¤ºæ–°é—»
        st.subheader(f"ğŸ“° {ticker} çœŸå®è´¢ç»æ–°é—»")
        
        for i, news in enumerate(news_data):
            advice = get_investment_advice(news['sentiment'])
            
            with st.container():
                col_main, col_side = st.columns([3, 1])
                
                with col_main:
                    st.markdown(f"### ğŸ“° {news['title']}")
                    
                    time_str = news['published'].strftime('%Y-%m-%d %H:%M')
                    st.caption(f"ğŸ•’ {time_str} | ğŸ“¡ {news['source']}")
                    
                    st.write(news['summary'])
                    
                    if news['keywords']:
                        keywords_str = " ".join([f"`{kw}`" for kw in news['keywords']])
                        st.markdown(f"**ğŸ·ï¸ å…³é”®è¯:** {keywords_str}")
                    
                    if news['url']:
                        st.markdown(f"ğŸ”— [é˜…è¯»åŸæ–‡]({news['url']})")
                    
                    # æ˜¾ç¤ºåŸå§‹æ•°æ®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    if news.get('raw_data') and show_raw_data:
                        with st.expander("ğŸ” åŸå§‹æ•°æ®"):
                            st.json(news['raw_data'])
                
                with col_side:
                    st.markdown(f"### {advice['icon']}")
                    st.markdown(f"**<span style='color:{advice['color']}'>{news['sentiment']}</span>**", unsafe_allow_html=True)
                    
                    st.write("**ğŸ“‹ å¸‚åœºå½±å“:**")
                    st.write(advice['advice'])
                    
                    st.write("**ğŸ’¡ æ“ä½œå»ºè®®:**")
                    st.write(advice['action'])
            
            st.markdown("---")
    
    else:
        st.warning("ğŸ“­ æœªè·å–åˆ°çœŸå®æ–°é—»æ•°æ®")
        
        if st.session_state.debug_info:
            st.subheader("ğŸ” è°ƒè¯•ä¿¡æ¯")
            for info in st.session_state.debug_info:
                st.write(info)
        
        st.markdown("### ğŸ’¡ å¯èƒ½çš„åŸå› ï¼š")
        st.markdown("""
        1. **APIé™åˆ¶**: Yahoo Financeå¯èƒ½æš‚æ—¶é™åˆ¶è®¿é—®
        2. **ç½‘ç»œé—®é¢˜**: æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸
        3. **è‚¡ç¥¨ä»£ç **: ç¡®è®¤è¾“å…¥çš„æ˜¯æœ‰æ•ˆçš„ç¾è‚¡ä»£ç 
        4. **æœåŠ¡çŠ¶æ€**: Yahoo FinanceæœåŠ¡å¯èƒ½æš‚æ—¶ä¸å¯ç”¨
        """)
        
        st.markdown("### ğŸ”§ å»ºè®®æ“ä½œï¼š")
        st.markdown("""
        - å¯ç”¨è°ƒè¯•æ¨¡å¼æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯
        - å°è¯•å…¶ä»–çŸ¥åè‚¡ç¥¨ä»£ç ï¼ˆå¦‚ AAPL, MSFTï¼‰
        - æ£€æŸ¥ç½‘ç»œè¿æ¥
        - ç¨åé‡è¯•
        """)

else:
    # æ¬¢è¿é¡µé¢
    st.markdown("""
    ## ğŸ¯ çœŸå®æ–°é—»è·å–ç³»ç»Ÿ
    
    ### âœ¨ æ ¸å¿ƒåŸåˆ™
    
    #### ğŸ“° **åªè·å–çœŸå®æ–°é—»**
    - âœ… ä»…ä»å®˜æ–¹APIè·å–çœŸå®æ–°é—»æ•°æ®
    - âŒ ç»ä¸ç”Ÿæˆæ¨¡æ‹Ÿæˆ–æ¨¡æ¿æ–°é—»
    - ğŸ” æä¾›è¯¦ç»†çš„æ•°æ®æ¥æºé€æ˜åº¦
    
    #### ğŸŒ **æ”¯æŒæ‰€æœ‰ç¾è‚¡**
    - ğŸ“ˆ æ”¯æŒä»»æ„ç¾è‚¡è‚¡ç¥¨ä»£ç 
    - ğŸ¢ æ— é¢„è®¾å…¬å¸åˆ—è¡¨é™åˆ¶
    - ğŸ”§ é€šç”¨çš„è´¢ç»æœ¯è¯­ç¿»è¯‘ç³»ç»Ÿ
    
    #### ğŸ›¡ï¸ **è¯šå®é€æ˜**
    - ğŸ“Š å¦‚æœæ— æ³•è·å–æ–°é—»ï¼Œè¯šå®å‘ŠçŸ¥
    - ğŸ” æä¾›è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
    - ğŸ“¡ æ˜¾ç¤ºçœŸå®çš„æ•°æ®æ¥æº
    
    ### ğŸš€ ä½¿ç”¨æ–¹æ³•
    
    1. **è¾“å…¥è‚¡ç¥¨ä»£ç ** - ä»»æ„ç¾è‚¡ä»£ç ï¼ˆå¦‚ AAPL, GOOGL, BRK.Aï¼‰
    2. **è·å–çœŸå®æ–°é—»** - ç³»ç»Ÿå°è¯•ä»å®˜æ–¹æºè·å–
    3. **æŸ¥çœ‹ç»“æœ** - å¦‚æœæˆåŠŸï¼Œæ˜¾ç¤ºç¿»è¯‘å’Œåˆ†æ
    4. **è°ƒè¯•æ”¯æŒ** - å¦‚æœå¤±è´¥ï¼Œæä¾›è¯¦ç»†çš„é—®é¢˜è¯Šæ–­
    
    ### ğŸ”§ æŠ€æœ¯ç‰¹è‰²
    
    - **å¤šé‡éªŒè¯**: éªŒè¯æ–°é—»æ•°æ®çš„å®Œæ•´æ€§å’ŒçœŸå®æ€§
    - **æ™ºèƒ½ç¿»è¯‘**: ä¸“ä¸šçš„è´¢ç»æœ¯è¯­ä¸­æ–‡ç¿»è¯‘
    - **æƒ…ç»ªåˆ†æ**: åŸºäºçœŸå®æ–°é—»å†…å®¹çš„AIåˆ†æ
    - **è°ƒè¯•æ¨¡å¼**: è¯¦ç»†çš„è·å–è¿‡ç¨‹é€æ˜åŒ–
    
    ### âš ï¸ é‡è¦è¯´æ˜
    
    æœ¬ç³»ç»Ÿæ‰¿è¯ºï¼š
    - ğŸ”’ **ç»ä¸ç”Ÿæˆå‡æ–°é—»**
    - ğŸ“° **åªå±•ç¤ºçœŸå®æ–°é—»æ•°æ®**
    - ğŸš« **APIå¤±è´¥æ—¶è¯šå®å‘ŠçŸ¥**
    - ğŸ” **æä¾›å®Œæ•´çš„é—®é¢˜è¯Šæ–­**
    
    ---
    
    **ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾“å…¥ä»»æ„ç¾è‚¡ä»£ç å¼€å§‹**
    """)
    
    with st.expander("ğŸ“– ç³»ç»Ÿè¯´æ˜"):
        st.markdown("""
        ### ğŸ¯ è®¾è®¡ç†å¿µ
        
        è¿™ä¸ªç³»ç»Ÿä¸“é—¨ä¸ºé‚£äº›éœ€è¦**çœŸå®è´¢ç»æ–°é—»**çš„ç”¨æˆ·è®¾è®¡ï¼š
        
        #### âœ… æˆ‘ä»¬åšä»€ä¹ˆ
        - ä»Yahoo Financeç­‰å®˜æ–¹æ¸ é“è·å–çœŸå®æ–°é—»
        - æä¾›ä¸“ä¸šçš„è´¢ç»æœ¯è¯­ç¿»è¯‘
        - è¿›è¡ŒåŸºäºçœŸå®å†…å®¹çš„æƒ…ç»ªåˆ†æ
        - åœ¨è·å–å¤±è´¥æ—¶æä¾›è¯¦ç»†çš„é—®é¢˜è¯Šæ–­
        
        #### âŒ æˆ‘ä»¬ä¸åšä»€ä¹ˆ
        - ä¸ç”Ÿæˆä»»ä½•æ¨¡æ‹Ÿæ–°é—»å†…å®¹
        - ä¸ä½¿ç”¨æ–°é—»æ¨¡æ¿æˆ–è™šå‡æ•°æ®
        - ä¸éšç’APIè·å–å¤±è´¥çš„æƒ…å†µ
        - ä¸é™åˆ¶ç‰¹å®šçš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
        
        ### ğŸ”§ æŠ€æœ¯å®ç°
        
        1. **çœŸå®æ€§éªŒè¯**: æ¯æ¡æ–°é—»éƒ½éªŒè¯æ ‡é¢˜ã€å†…å®¹å®Œæ•´æ€§
        2. **é”™è¯¯é€æ˜**: APIå¤±è´¥æ—¶æ˜¾ç¤ºå…·ä½“é”™è¯¯ä¿¡æ¯
        3. **è°ƒè¯•æ”¯æŒ**: è¯¦ç»†çš„è·å–è¿‡ç¨‹æ—¥å¿—
        4. **æºç å¼€æ”¾**: æ‰€æœ‰å¤„ç†é€»è¾‘å®Œå…¨é€æ˜
        
        ### ğŸ’¡ ä½¿ç”¨å»ºè®®
        
        - å¦‚æœé‡åˆ°è·å–å¤±è´¥ï¼Œå¯ç”¨è°ƒè¯•æ¨¡å¼æŸ¥çœ‹å…·ä½“åŸå› 
        - å°è¯•ä¸åŒçš„çŸ¥åè‚¡ç¥¨ä»£ç éªŒè¯ç³»ç»ŸåŠŸèƒ½
        - ç½‘ç»œé—®é¢˜æ—¶å¯ä»¥ç¨åé‡è¯•
        - æˆ‘ä»¬ç›¸ä¿¡é€æ˜æ¯”ä¾¿åˆ©æ›´é‡è¦
        """)

# é¡µè„š
st.markdown("---")
st.markdown("ğŸ“° çœŸå®æ–°é—»è·å–ç³»ç»Ÿ | ğŸ”’ åªæ˜¾ç¤ºçœŸå®æ•°æ® | ğŸš« æ‹’ç»è™šå‡å†…å®¹ | ğŸ” å®Œå…¨é€æ˜")
