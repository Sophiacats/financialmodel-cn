import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ğŸ’¹ æ™ºèƒ½æŠ•èµ„åˆ†æç³»ç»Ÿ",
    page_icon="ğŸ’¹",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ– session state
if 'current_ticker' not in st.session_state:
    st.session_state.current_ticker = None
if 'current_price' not in st.session_state:
    st.session_state.current_price = 0
if 'analysis_data' not in st.session_state:
    st.session_state.analysis_data = None
if 'show_analysis' not in st.session_state:
    st.session_state.show_analysis = False

# æ ‡é¢˜
st.title("ğŸ’¹ æ™ºèƒ½æŠ•èµ„åˆ†æç³»ç»Ÿ v2.0")
st.markdown("---")

@st.cache_data(ttl=3600)
def fetch_stock_data(ticker):
    """è·å–è‚¡ç¥¨æ•°æ®"""
    try:
        stock = yf.Ticker(ticker)
        info = dict(stock.info)
        
        end_date = datetime.now()
        start_date = end_date - timedelta(days=365*2)
        hist_data = stock.history(start=start_date, end=end_date)
        
        financials = stock.financials
        balance_sheet = stock.balance_sheet
        cash_flow = stock.cashflow
        
        return {
            'info': info,
            'hist_data': hist_data.copy(),
            'financials': financials.copy() if financials is not None else pd.DataFrame(),
            'balance_sheet': balance_sheet.copy() if balance_sheet is not None else pd.DataFrame(),
            'cash_flow': cash_flow.copy() if cash_flow is not None else pd.DataFrame()
        }
    except Exception as e:
        st.error(f"è·å–æ•°æ®å¤±è´¥: {str(e)}")
        return None

def translate_to_chinese(text):
    """ä½¿ç”¨åœ¨çº¿ç¿»è¯‘æœåŠ¡å°†è‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡"""
    if not text or len(text.strip()) < 3:
        return text
    
    try:
        # æ–¹æ³•1: ä½¿ç”¨googletransåº“ (å¦‚æœå¯ç”¨)
        try:
            from googletrans import Translator
            translator = Translator()
            result = translator.translate(text, src='en', dest='zh-cn')
            return result.text
        except ImportError:
            pass
        except Exception:
            pass
        
        # æ–¹æ³•2: ä½¿ç”¨requestsè°ƒç”¨Googleç¿»è¯‘API
        try:
            import requests
            import urllib.parse
            
            # Googleç¿»è¯‘API (å…è´¹ç‰ˆæœ¬)
            url = "https://translate.googleapis.com/translate_a/single"
            params = {
                'client': 'gtx',
                'sl': 'en',
                'tl': 'zh-cn',
                'dt': 't',
                'q': text
            }
            
            response = requests.get(url, params=params, timeout=5)
            if response.status_code == 200:
                result = response.json()
                if result and len(result) > 0 and len(result[0]) > 0:
                    translated_text = ''.join([item[0] for item in result[0] if item[0]])
                    return translated_text
        except:
            pass
        
        # æ–¹æ³•3: ä½¿ç”¨ç™¾åº¦ç¿»è¯‘API (å¤‡ç”¨)
        try:
            import requests
            import hashlib
            import random
            
            # è¿™é‡Œå¯ä»¥æ·»åŠ ç™¾åº¦ç¿»è¯‘APIçš„è°ƒç”¨
            # éœ€è¦ç”³è¯·APIå¯†é’¥
            pass
        except:
            pass
        
        # å¦‚æœæ‰€æœ‰ç¿»è¯‘æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›åŸæ–‡
        return text
        
    except Exception as e:
        # å¦‚æœç¿»è¯‘å¤±è´¥ï¼Œè¿”å›åŸæ–‡
        return text

def fetch_financial_news(target_ticker=None):
    """è·å–çœŸå®è´¢ç»æ–°é—»ï¼ˆä»…çœŸå®æ–°é—»ï¼‰"""
    try:
        current_time = datetime.now()
        news_data = []
        
        # è·å–ç›®æ ‡è‚¡ç¥¨æ–°é—»
        if target_ticker:
            try:
                ticker_obj = yf.Ticker(target_ticker)
                news = ticker_obj.news
                
                if news and len(news) > 0:
                    for i, article in enumerate(news[:8]):  # è·å–å‰8æ¡çœŸå®æ–°é—»
                        try:
                            # æ–°çš„APIç»“æ„ï¼šæ•°æ®åœ¨contentå­—æ®µé‡Œ
                            content = article.get('content', article)  # å…¼å®¹æ–°æ—§ç»“æ„
                            
                            title = content.get('title', '') or content.get('headline', '') or article.get('title', '')
                            summary = content.get('summary', '') or content.get('description', '') or content.get('snippet', '')
                            
                            # è·å–é“¾æ¥
                            link = ''
                            if 'clickThroughUrl' in content and content['clickThroughUrl']:
                                link = content['clickThroughUrl'].get('url', '')
                            elif 'canonicalUrl' in content and content['canonicalUrl']:
                                link = content['canonicalUrl'].get('url', '')
                            else:
                                link = content.get('link', '') or content.get('url', '')
                            
                            # è·å–å‘å¸ƒè€…
                            publisher = 'Unknown'
                            if 'provider' in content and content['provider']:
                                publisher = content['provider'].get('displayName', 'Unknown')
                            else:
                                publisher = content.get('publisher', '') or content.get('source', 'Unknown')
                            
                            # è·å–æ—¶é—´
                            pub_time = None
                            pub_date_str = content.get('pubDate', '') or content.get('displayTime', '')
                            if pub_date_str:
                                try:
                                    # å¤„ç†ISOæ ¼å¼çš„æ—¶é—´å­—ç¬¦ä¸²
                                    if 'T' in pub_date_str and 'Z' in pub_date_str:
                                        published_time = datetime.fromisoformat(pub_date_str.replace('Z', '+00:00')).replace(tzinfo=None)
                                    else:
                                        published_time = current_time - timedelta(hours=i+1)
                                except:
                                    published_time = current_time - timedelta(hours=i+1)
                            else:
                                # å°è¯•æ•°å­—æ—¶é—´æˆ³
                                pub_time = content.get('providerPublishTime', None) or article.get('providerPublishTime', None)
                                if pub_time:
                                    try:
                                        published_time = datetime.fromtimestamp(pub_time)
                                    except:
                                        published_time = current_time - timedelta(hours=i+1)
                                else:
                                    published_time = current_time - timedelta(hours=i+1)
                            
                            if title and len(title.strip()) > 5:  # ç¡®ä¿æ ‡é¢˜æœ‰å®é™…å†…å®¹
                                # ç¿»è¯‘æ ‡é¢˜å’Œæ‘˜è¦
                                try:
                                    translated_title = translate_to_chinese(title)
                                    if summary and len(summary.strip()) > 10:
                                        translated_summary = translate_to_chinese(summary)
                                    else:
                                        translated_summary = 'æš‚æ— æ‘˜è¦'
                                except:
                                    # å¦‚æœç¿»è¯‘å¤±è´¥ï¼Œä½¿ç”¨åŸæ–‡
                                    translated_title = title
                                    translated_summary = summary or 'æš‚æ— æ‘˜è¦'
                                
                                # æå–å…³é”®è¯å’Œåˆ†ææƒ…ç»ª
                                title_summary = title + ' ' + (summary or '')
                                keywords = extract_keywords_from_text(title_summary)
                                sentiment = analyze_sentiment_from_keywords(keywords)
                                
                                news_item = {
                                    "title": translated_title,
                                    "summary": translated_summary[:300] + '...' if len(translated_summary) > 300 else translated_summary,
                                    "published": published_time,
                                    "url": link or '',
                                    "source": publisher,
                                    "category": "company_specific",
                                    "keywords": keywords,
                                    "sentiment": sentiment,
                                    "is_real": True
                                }
                                news_data.append(news_item)
                        except Exception as e:
                            continue
                            
            except Exception as e:
                pass
        
        # è·å–å¸‚åœºæ•´ä½“æ–°é—»
        try:
            market_indices = ["^GSPC", "^IXIC", "^DJI"]
            for index_symbol in market_indices:
                try:
                    index_ticker = yf.Ticker(index_symbol)
                    index_news = index_ticker.news
                    
                    if index_news and len(index_news) > 0:
                        for j, article in enumerate(index_news[:3]):  # æ¯ä¸ªæŒ‡æ•°å–3æ¡
                            try:
                                # æ–°çš„APIç»“æ„ï¼šæ•°æ®åœ¨contentå­—æ®µé‡Œ
                                content = article.get('content', article)
                                
                                title = content.get('title', '') or content.get('headline', '') or article.get('title', '')
                                summary = content.get('summary', '') or content.get('description', '') or content.get('snippet', '')
                                
                                # è·å–é“¾æ¥
                                link = ''
                                if 'clickThroughUrl' in content and content['clickThroughUrl']:
                                    link = content['clickThroughUrl'].get('url', '')
                                elif 'canonicalUrl' in content and content['canonicalUrl']:
                                    link = content['canonicalUrl'].get('url', '')
                                else:
                                    link = content.get('link', '') or content.get('url', '')
                                
                                # è·å–å‘å¸ƒè€…
                                publisher = 'Market News'
                                if 'provider' in content and content['provider']:
                                    publisher = content['provider'].get('displayName', 'Market News')
                                else:
                                    publisher = content.get('publisher', '') or content.get('source', 'Market News')
                                
                                # è·å–æ—¶é—´
                                pub_date_str = content.get('pubDate', '') or content.get('displayTime', '')
                                if pub_date_str:
                                    try:
                                        if 'T' in pub_date_str and 'Z' in pub_date_str:
                                            published_time = datetime.fromisoformat(pub_date_str.replace('Z', '+00:00')).replace(tzinfo=None)
                                        else:
                                            published_time = current_time - timedelta(hours=len(news_data)+1)
                                    except:
                                        published_time = current_time - timedelta(hours=len(news_data)+1)
                                else:
                                    published_time = current_time - timedelta(hours=len(news_data)+1)
                                
                                if title and len(title.strip()) > 5:  # ç¡®ä¿æ ‡é¢˜æœ‰å®é™…å†…å®¹
                                    # é¿å…é‡å¤æ–°é—»
                                    if not any(existing['title'] == title for existing in news_data):
                                        # ç¿»è¯‘æ ‡é¢˜å’Œæ‘˜è¦
                                        try:
                                            translated_title = translate_to_chinese(title)
                                            if summary and len(summary.strip()) > 10:
                                                translated_summary = translate_to_chinese(summary)
                                            else:
                                                translated_summary = 'æš‚æ— æ‘˜è¦'
                                        except:
                                            # å¦‚æœç¿»è¯‘å¤±è´¥ï¼Œä½¿ç”¨åŸæ–‡
                                            translated_title = title
                                            translated_summary = summary or 'æš‚æ— æ‘˜è¦'
                                        
                                        title_summary = title + ' ' + (summary or '')
                                        keywords = extract_keywords_from_text(title_summary)
                                        sentiment = analyze_sentiment_from_keywords(keywords)
                                        
                                        news_item = {
                                            "title": translated_title,
                                            "summary": translated_summary[:300] + '...' if len(translated_summary) > 300 else translated_summary,
                                            "published": published_time,
                                            "url": link or '',
                                            "source": publisher,
                                            "category": "market_wide",
                                            "keywords": keywords,
                                            "sentiment": sentiment,
                                            "is_real": True
                                        }
                                        news_data.append(news_item)
                            except Exception as e:
                                continue
                except Exception as e:
                    continue
        except Exception as e:
            pass
        
        # æŒ‰æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
        news_data.sort(key=lambda x: x.get('published', datetime.now()), reverse=True)
        
        # å¦‚æœä»ç„¶æ²¡æœ‰æ–°é—»ï¼Œæä¾›ç³»ç»Ÿæç¤º
        if len(news_data) == 0:
            return [{
                "title": "æ–°é—»è·å–æœåŠ¡æš‚æ—¶ä¸å¯ç”¨",
                "summary": "ç”±äºæŠ€æœ¯åŸå› ï¼Œæš‚æ—¶æ— æ³•è·å–å®æ—¶è´¢ç»æ–°é—»ã€‚è¯·ç›´æ¥è®¿é—®Yahoo Financeã€Bloombergç­‰è´¢ç»ç½‘ç«™è·å–æœ€æ–°å¸‚åœºä¿¡æ¯ã€‚",
                "published": current_time,
                "url": "https://finance.yahoo.com",
                "source": "ç³»ç»Ÿæç¤º",
                "category": "system_info",
                "keywords": ["ç³»ç»Ÿ", "æç¤º"],
                "sentiment": "ä¸­æ€§",
                "is_real": False
            }]
        
        return news_data
        
    except Exception as e:
        # è¿”å›ä¸€ä¸ªåŸºæœ¬çš„ç³»ç»Ÿä¿¡æ¯
        return [{
            "title": "æ–°é—»è·å–æœåŠ¡æš‚æ—¶ä¸å¯ç”¨",
            "summary": "ç”±äºæŠ€æœ¯åŸå› ï¼Œæš‚æ—¶æ— æ³•è·å–å®æ—¶è´¢ç»æ–°é—»ã€‚è¯·ç›´æ¥è®¿é—®è´¢ç»ç½‘ç«™è·å–æœ€æ–°å¸‚åœºä¿¡æ¯ã€‚",
            "published": datetime.now(),
            "url": "",
            "source": "ç³»ç»Ÿ",
            "category": "system_info",
            "keywords": ["ç³»ç»Ÿ"],
            "sentiment": "ä¸­æ€§",
            "is_real": False
        }]

def extract_keywords_from_text(text):
    """ä»æ–‡æœ¬ä¸­æå–è´¢ç»å…³é”®è¯"""
    if not text:
        return []
    
    text_lower = text.lower()
    
    # è´¢ç»å…³é”®è¯åº“
    keyword_categories = {
        "åˆ©ç‡": ["rate", "interest", "fed", "federal reserve", "åˆ©ç‡", "é™æ¯", "åŠ æ¯"],
        "ç§‘æŠ€": ["tech", "technology", "ai", "artificial intelligence", "chip", "semiconductor", "ç§‘æŠ€", "äººå·¥æ™ºèƒ½", "èŠ¯ç‰‡"],
        "é‡‘è": ["bank", "financial", "finance", "credit", "loan", "é“¶è¡Œ", "é‡‘è", "ä¿¡è´·"],
        "èƒ½æº": ["energy", "oil", "gas", "petroleum", "renewable", "èƒ½æº", "çŸ³æ²¹", "å¤©ç„¶æ°”"],
        "ä¸Šæ¶¨": ["up", "rise", "gain", "increase", "rally", "surge", "ä¸Šæ¶¨", "å¢é•¿", "ä¸Šå‡"],
        "ä¸‹è·Œ": ["down", "fall", "drop", "decline", "crash", "ä¸‹è·Œ", "ä¸‹é™", "æš´è·Œ"],
        "é€šèƒ€": ["inflation", "cpi", "consumer price", "é€šèƒ€", "ç‰©ä»·"],
        "æ”¿ç­–": ["policy", "regulation", "government", "æ”¿ç­–", "ç›‘ç®¡", "æ”¿åºœ"],
        "ç»æµå¢é•¿": ["growth", "gdp", "economic", "economy", "ç»æµ", "å¢é•¿"],
        "å¸‚åœº": ["market", "stock", "trading", "investor", "å¸‚åœº", "è‚¡ç¥¨", "æŠ•èµ„"]
    }
    
    found_keywords = []
    for category, words in keyword_categories.items():
        for word in words:
            if word in text_lower:
                found_keywords.append(category)
                break
    
    return found_keywords[:5]

def analyze_sentiment_from_keywords(keywords):
    """æ ¹æ®å…³é”®è¯åˆ†ææƒ…ç»ª"""
    bullish_words = ["ä¸Šæ¶¨", "å¢é•¿", "åˆ©ç‡", "ç§‘æŠ€", "ç»æµå¢é•¿"]
    bearish_words = ["ä¸‹è·Œ", "é€šèƒ€", "æ”¿ç­–"]
    
    bullish_count = sum(1 for kw in keywords if kw in bullish_words)
    bearish_count = sum(1 for kw in keywords if kw in bearish_words)
    
    if bullish_count > bearish_count:
        return "åˆ©å¥½"
    elif bearish_count > bullish_count:
        return "åˆ©ç©º"
    else:
        return "ä¸­æ€§"

def get_market_impact_advice(sentiment):
    """æ ¹æ®æƒ…ç»ªç»™å‡ºå¸‚åœºå½±å“å»ºè®®"""
    if sentiment == "åˆ©å¥½":
        return {
            "icon": "ğŸ“ˆ",
            "advice": "ç§¯æå› ç´ ï¼Œå¯å…³æ³¨ç›¸å…³æ¿å—æœºä¼š",
            "action": "å»ºè®®å…³æ³¨ç›¸å…³æ¦‚å¿µè‚¡ï¼Œé€‚å½“å¢åŠ ä»“ä½"
        }
    elif sentiment == "åˆ©ç©º":
        return {
            "icon": "ğŸ“‰", 
            "advice": "é£é™©å› ç´ ï¼Œå»ºè®®è°¨æ…æ“ä½œ",
            "action": "é™ä½é£é™©æ•å£ï¼Œå…³æ³¨é˜²å¾¡æ€§æ¿å—"
        }
    else:
        return {
            "icon": "ğŸ“Š",
            "advice": "ä¸­æ€§å½±å“ï¼Œç»´æŒç°æœ‰ç­–ç•¥",
            "action": "å¯†åˆ‡å…³æ³¨åç»­å‘å±•ï¼Œä¿æŒçµæ´»æ“ä½œ"
        }

def calculate_technical_indicators(hist_data):
    """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡"""
    try:
        hist_data['MA10'] = hist_data['Close'].rolling(window=10).mean()
        hist_data['MA20'] = hist_data['Close'].rolling(window=20).mean()
        hist_data['MA60'] = hist_data['Close'].rolling(window=60).mean()
        
        exp1 = hist_data['Close'].ewm(span=12, adjust=False).mean()
        exp2 = hist_data['Close'].ewm(span=26, adjust=False).mean()
        hist_data['MACD'] = exp1 - exp2
        hist_data['Signal'] = hist_data['MACD'].ewm(span=9, adjust=False).mean()
        hist_data['MACD_Histogram'] = hist_data['MACD'] - hist_data['Signal']
        
        delta = hist_data['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        hist_data['RSI'] = 100 - (100 / (1 + rs))
        
        hist_data['BB_Middle'] = hist_data['Close'].rolling(window=20).mean()
        bb_std = hist_data['Close'].rolling(window=20).std()
        hist_data['BB_Upper'] = hist_data['BB_Middle'] + (bb_std * 2)
        hist_data['BB_Lower'] = hist_data['BB_Middle'] - (bb_std * 2)
        
        return hist_data
    except Exception as e:
        st.warning(f"æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¤±è´¥: {str(e)}")
        return hist_data

def calculate_piotroski_score(data):
    """è®¡ç®—Piotroski F-Score"""
    score = 0
    reasons = []
    
    try:
        financials = data['financials']
        balance_sheet = data['balance_sheet']
        cash_flow = data['cash_flow']
        
        if financials.empty or balance_sheet.empty or cash_flow.empty:
            return 0, ["âŒ è´¢åŠ¡æ•°æ®ä¸å®Œæ•´"]
        
        # 1. å‡€åˆ©æ¶¦
        if len(financials.columns) >= 1 and 'Net Income' in financials.index:
            net_income = financials.loc['Net Income'].iloc[0]
            if net_income > 0:
                score += 1
                reasons.append("âœ… å‡€åˆ©æ¶¦ä¸ºæ­£")
            else:
                reasons.append("âŒ å‡€åˆ©æ¶¦ä¸ºè´Ÿ")
        
        # 2. ç»è¥ç°é‡‘æµ
        if len(cash_flow.columns) >= 1 and 'Operating Cash Flow' in cash_flow.index:
            ocf = cash_flow.loc['Operating Cash Flow'].iloc[0]
            if ocf > 0:
                score += 1
                reasons.append("âœ… ç»è¥ç°é‡‘æµä¸ºæ­£")
            else:
                reasons.append("âŒ ç»è¥ç°é‡‘æµä¸ºè´Ÿ")
        
        # ç®€åŒ–å…¶ä»–æŒ‡æ ‡
        score += 5
        reasons.append("ğŸ“Š å…¶ä»–è´¢åŠ¡æŒ‡æ ‡åŸºç¡€åˆ†: 5åˆ†")
        
    except Exception as e:
        return 0, ["âŒ è®¡ç®—è¿‡ç¨‹å‡ºç°é”™è¯¯"]
    
    return score, reasons

def calculate_dcf_valuation(data):
    """DCFä¼°å€¼æ¨¡å‹"""
    try:
        info = data['info']
        cash_flow = data['cash_flow']
        
        if cash_flow.empty:
            return None, None
        
        # è·å–è‡ªç”±ç°é‡‘æµ
        fcf = 0
        if 'Free Cash Flow' in cash_flow.index and len(cash_flow.columns) > 0:
            fcf = cash_flow.loc['Free Cash Flow'].iloc[0]
        elif 'Operating Cash Flow' in cash_flow.index and len(cash_flow.columns) > 0:
            ocf = cash_flow.loc['Operating Cash Flow'].iloc[0]
            capex = cash_flow.loc['Capital Expenditure'].iloc[0] if 'Capital Expenditure' in cash_flow.index else 0
            fcf = ocf + capex
        
        if fcf <= 0:
            return None, None
        
        # DCFå‚æ•°
        growth_rate = 0.05
        discount_rate = 0.10
        terminal_growth = 0.02
        forecast_years = 5
        
        # è®¡ç®—é¢„æµ‹æœŸç°é‡‘æµç°å€¼
        dcf_value = 0
        for i in range(1, forecast_years + 1):
            future_fcf = fcf * (1 + growth_rate) ** i
            pv = future_fcf / (1 + discount_rate) ** i
            dcf_value += pv
        
        # è®¡ç®—ç»ˆå€¼
        terminal_fcf = fcf * (1 + growth_rate) ** forecast_years * (1 + terminal_growth)
        terminal_value = terminal_fcf / (discount_rate - terminal_growth)
        terminal_pv = terminal_value / (1 + discount_rate) ** forecast_years
        
        enterprise_value = dcf_value + terminal_pv
        
        shares = info.get('sharesOutstanding', 0)
        if shares <= 0:
            return None, None
            
        fair_value_per_share = enterprise_value / shares
        
        if fair_value_per_share < 0 or fair_value_per_share > 10000:
            return None, None
            
        return fair_value_per_share, {
            'growth_rate': growth_rate,
            'discount_rate': discount_rate,
            'terminal_growth': terminal_growth,
            'enterprise_value': enterprise_value
        }
    except Exception as e:
        return None, None

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("ğŸ“Š åˆ†æå‚æ•°è®¾ç½®")
    
    ticker = st.text_input("è‚¡ç¥¨ä»£ç ", "AAPL", help="è¾“å…¥è‚¡ç¥¨ä»£ç ï¼Œå¦‚ï¼šAAPL")
    analyze_button = st.button("ğŸ” å¼€å§‹åˆ†æ", type="primary", use_container_width=True)
    
    with st.expander("ğŸ“˜ ä½¿ç”¨è¯´æ˜"):
        st.markdown("""
        ### ç³»ç»ŸåŠŸèƒ½
        1. **è‚¡ç¥¨åˆ†æ**: è´¢åŠ¡æŒ‡æ ‡ã€æŠ€æœ¯åˆ†æã€ä¼°å€¼æ¨¡å‹
        2. **æ–°é—»åˆ†æ**: çœŸå®æ–°é—»è·å–ä¸åˆ†æ
        3. **æ­¢ç›ˆæ­¢æŸ**: æ™ºèƒ½ç­–ç•¥å»ºè®®
        
        ### æ“ä½œæ–¹æ³•
        1. è¾“å…¥è‚¡ç¥¨ä»£ç ï¼ˆå¦‚AAPLã€TSLAã€MSFTï¼‰
        2. ç‚¹å‡»"å¼€å§‹åˆ†æ"
        3. æŸ¥çœ‹åˆ†æç»“æœå’Œæ–°é—»
        
        ### æ³¨æ„äº‹é¡¹
        - ä»…æ˜¾ç¤ºçœŸå®æ–°é—»ï¼Œæ— æ¨¡æ‹Ÿå†…å®¹
        - æ–°é—»æ•°é‡å–å†³äºå®é™…å¯è·å–çš„æ•°æ®
        """)

# ä¸»ç•Œé¢é€»è¾‘
if analyze_button and ticker:
    st.session_state.current_ticker = ticker
    st.session_state.show_analysis = True
    
    with st.spinner(f"æ­£åœ¨è·å– {ticker} çš„æ•°æ®..."):
        data = fetch_stock_data(ticker)
    
    if data:
        current_price = data['info'].get('currentPrice', 0)
        st.session_state.current_price = current_price
        st.session_state.analysis_data = data

# æ˜¾ç¤ºåˆ†æç»“æœ
if st.session_state.show_analysis and st.session_state.analysis_data is not None:
    data = st.session_state.analysis_data
    current_price = st.session_state.current_price
    ticker = st.session_state.current_ticker
    
    # ä¸»åŠŸèƒ½æ ‡ç­¾é¡µ
    main_tab1, main_tab2 = st.tabs(["ğŸ“Š è‚¡ç¥¨åˆ†æ", "ğŸ“° çœŸå®æ–°é—»åˆ†æ"])
    
    with main_tab1:
        col1, col2, col3 = st.columns([1, 2, 1])
        
        # å·¦æ ï¼šåŸºæœ¬ä¿¡æ¯
        with col1:
            st.subheader("ğŸ“Œ å…¬å¸åŸºæœ¬ä¿¡æ¯")
            info = data['info']
            
            st.metric("å…¬å¸åç§°", info.get('longName', ticker))
            st.metric("å½“å‰è‚¡ä»·", f"${current_price:.2f}")
            st.metric("å¸‚å€¼", f"${info.get('marketCap', 0)/1e9:.2f}B")
            st.metric("è¡Œä¸š", info.get('industry', 'N/A'))
            st.metric("Beta", f"{info.get('beta', 0):.2f}")
        
        # ä¸­æ ï¼šè´¢åŠ¡åˆ†æ
        with col2:
            st.subheader("ğŸ“ˆ è´¢åŠ¡åˆ†æ")
            
            # Piotroski F-Score
            with st.expander("ğŸ” Piotroski F-Score åˆ†æ", expanded=True):
                f_score, reasons = calculate_piotroski_score(data)
                
                score_color = "green" if f_score >= 7 else "orange" if f_score >= 4 else "red"
                st.markdown(f"### å¾—åˆ†: <span style='color:{score_color}; font-size:24px'>{f_score}/9</span>", unsafe_allow_html=True)
                
                for reason in reasons:
                    st.write(reason)
            
            # DCFä¼°å€¼åˆ†æ
            with st.expander("ğŸ’ DCFä¼°å€¼åˆ†æ", expanded=True):
                dcf_value, dcf_params = calculate_dcf_valuation(data)
                
                if dcf_value and current_price > 0:
                    col_x, col_y = st.columns(2)
                    with col_x:
                        st.metric("åˆç†ä»·å€¼", f"${dcf_value:.2f}")
                        st.metric("å½“å‰ä»·æ ¼", f"${current_price:.2f}")
                    with col_y:
                        margin = ((dcf_value - current_price) / dcf_value * 100) if dcf_value > 0 else 0
                        st.metric("å®‰å…¨è¾¹é™…", f"{margin:.2f}%")
                        
                        if margin > 20:
                            st.success("ğŸ“ˆ æ˜æ˜¾ä½ä¼°")
                        elif margin > 0:
                            st.info("ğŸ“Š åˆç†ä¼°å€¼")
                        else:
                            st.warning("ğŸ“‰ å¯èƒ½é«˜ä¼°")
                else:
                    st.info("DCFä¼°å€¼æ•°æ®ä¸è¶³")
        
        # å³æ ï¼šæŠ€æœ¯åˆ†æ
        with col3:
            st.subheader("ğŸ“‰ æŠ€æœ¯åˆ†æ")
            
            # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
            hist_data = data['hist_data'].copy()
            hist_data = calculate_technical_indicators(hist_data)
            
            if len(hist_data) > 0:
                latest = hist_data.iloc[-1]
                
                # RSIçŠ¶æ€
                if 'RSI' in hist_data.columns:
                    rsi_value = latest['RSI']
                    if rsi_value > 70:
                        st.error(f"âš ï¸ RSI: {rsi_value:.1f} (è¶…ä¹°)")
                    elif rsi_value < 30:
                        st.success(f"ğŸ’¡ RSI: {rsi_value:.1f} (è¶…å–)")
                    else:
                        st.info(f"ğŸ“Š RSI: {rsi_value:.1f} (æ­£å¸¸)")
                
                # å‡çº¿çŠ¶æ€
                if 'MA10' in hist_data.columns and 'MA60' in hist_data.columns:
                    if latest['MA10'] > latest['MA60']:
                        st.info("ğŸ“ˆ å‡çº¿ï¼šå¤šå¤´æ’åˆ—")
                    else:
                        st.warning("ğŸ“‰ å‡çº¿ï¼šç©ºå¤´æ’åˆ—")
            
            # ç®€åŒ–çš„æ­¢ç›ˆæ­¢æŸè®¡ç®—
            st.markdown("### ğŸ’° æ­¢ç›ˆæ­¢æŸå»ºè®®")
            
            default_buy_price = current_price * 0.95
            buy_price = st.number_input(
                "å‡è®¾ä¹°å…¥ä»·æ ¼ ($)", 
                min_value=0.01, 
                value=default_buy_price, 
                step=0.01
            )
            
            # å›ºå®šæ¯”ä¾‹æ³•
            stop_loss = buy_price * 0.90  # 10%æ­¢æŸ
            take_profit = buy_price * 1.15  # 15%æ­¢ç›ˆ
            
            col_sl, col_tp = st.columns(2)
            with col_sl:
                st.metric("ğŸ›¡ï¸ å»ºè®®æ­¢æŸ", f"${stop_loss:.2f}")
            with col_tp:
                st.metric("ğŸ¯ å»ºè®®æ­¢ç›ˆ", f"${take_profit:.2f}")
            
            # å½“å‰çŠ¶æ€
            if current_price <= stop_loss:
                st.error("âš ï¸ å·²è§¦åŠæ­¢æŸçº¿ï¼")
            elif current_price >= take_profit:
                st.success("ğŸ¯ å·²è¾¾åˆ°æ­¢ç›ˆç›®æ ‡ï¼")
            else:
                st.info("ğŸ“Š æŒä»“æ­£å¸¸")
    
    with main_tab2:
        st.subheader("ğŸ“° çœŸå®æ–°é—»åˆ†æ")
        st.info("ğŸ’¡ åŸºäºçœŸå®è´¢ç»æ–°é—»çš„å¸‚åœºå½±å“åˆ†æï¼ˆä¸å«ä»»ä½•æ¨¡æ‹Ÿå†…å®¹ï¼‰")
        
        # è·å–çœŸå®æ–°é—»æ•°æ®
        news_data = fetch_financial_news(ticker)
        
        if len(news_data) == 0:
            st.warning("âš ï¸ æš‚æ—¶æ— æ³•è·å–æ–°é—»æ•°æ®ï¼Œè¯·ç¨åé‡è¯•æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥")
            st.info("ğŸ’¡ å»ºè®®ç›´æ¥è®¿é—®è´¢ç»ç½‘ç«™è·å–æœ€æ–°å¸‚åœºåŠ¨æ€")
        else:
            # æ–°é—»ç»Ÿè®¡
            total_news = len(news_data)
            company_news = len([n for n in news_data if n.get('category') == 'company_specific'])
            market_news = len([n for n in news_data if n.get('category') == 'market_wide'])
            
            col_stat1, col_stat2, col_stat3 = st.columns(3)
            with col_stat1:
                st.metric("ğŸ“° çœŸå®æ–°é—»", total_news)
            with col_stat2:
                st.metric("ğŸ¢ å…¬å¸ç›¸å…³", company_news)
            with col_stat3:
                st.metric("ğŸŒ å¸‚åœºå½±å“", market_news)
            
            st.markdown("---")
            
            # åˆ†é¡µè®¾ç½®
            news_per_page = 5
            total_pages = (len(news_data) + news_per_page - 1) // news_per_page
            
            # åˆå§‹åŒ–å½“å‰é¡µ
            if 'current_news_page' not in st.session_state:
                st.session_state.current_news_page = 1
            
            # ç¡®ä¿é¡µæ•°åœ¨æœ‰æ•ˆèŒƒå›´å†…
            if st.session_state.current_news_page > total_pages:
                st.session_state.current_news_page = total_pages
            if st.session_state.current_news_page < 1:
                st.session_state.current_news_page = 1
            
            current_page = st.session_state.current_news_page
            
            # è®¡ç®—å½“å‰é¡µæ–°é—»
            start_idx = (current_page - 1) * news_per_page
            end_idx = min(start_idx + news_per_page, len(news_data))
            current_news = news_data[start_idx:end_idx]
            
            st.markdown(f"### ğŸ“„ ç¬¬ {current_page} é¡µ (æ˜¾ç¤ºç¬¬ {start_idx + 1}-{end_idx} æ¡æ–°é—»)")
            
            # æ˜¾ç¤ºæ–°é—»
            for i, news in enumerate(current_news):
                category = news.get('category', 'general')
                
                # è®¾ç½®è¾¹æ¡†é¢œè‰²
                if category == 'company_specific':
                    border_color = "#4CAF50"  # ç»¿è‰²
                elif category == 'market_wide':
                    border_color = "#2196F3"  # è“è‰²
                else:
                    border_color = "#FF9800"  # æ©™è‰²
                
                # åˆ†ç±»æ ‡ç­¾
                category_labels = {
                    'company_specific': f'ğŸ¢ {ticker}ç›¸å…³',
                    'market_wide': 'ğŸŒ å¸‚åœºå½±å“',
                    'industry_specific': 'ğŸ­ è¡Œä¸šåŠ¨æ€'
                }
                category_label = category_labels.get(category, 'ğŸ“° ä¸€èˆ¬æ–°é—»')
                
                news_number = start_idx + i + 1
                
                st.markdown(f"""
                <div style="border: 2px solid {border_color}; border-radius: 10px; padding: 15px; margin: 10px 0;">
                    <div style="display: flex; justify-content: space-between; margin-bottom: 8px;">
                        <span style="background-color: {border_color}; color: white; padding: 2px 8px; border-radius: 12px; font-size: 11px;">
                            {news_number}. {category_label} | âœ… çœŸå®æ–°é—»
                        </span>
                        <span style="font-size: 11px; color: #999;">ğŸ“° {news.get('source', '')}</span>
                    </div>
                    <p style="color: #666; margin: 10px 0;">{news.get('summary', '')}</p>
                    <p style="font-size: 12px; color: #999;">
                        ğŸ“… {news.get('published', datetime.now()).strftime('%Y-%m-%d %H:%M')} | 
                        ğŸ·ï¸ å…³é”®è¯: {', '.join(news.get('keywords', []))}
                    </p>
                </div>
                """, unsafe_allow_html=True)
                
                # æ–°é—»æ ‡é¢˜æŒ‰é’®ï¼ˆçœŸå®é“¾æ¥ï¼‰
                news_url = news.get('url', '')
                news_title = news.get('title', 'æ— æ ‡é¢˜')
                
                if news_url and news_url.startswith('http'):
                    st.markdown(f'<a href="{news_url}" target="_blank"><button style="background: linear-gradient(45deg, {border_color}, {border_color}dd); color: white; border: none; padding: 12px 20px; border-radius: 8px; cursor: pointer; font-size: 14px; font-weight: bold; width: 100%; margin: 10px 0;">ğŸ”— {news_title}</button></a>', unsafe_allow_html=True)
                else:
                    st.markdown(f'<button style="background: linear-gradient(45deg, #999, #777); color: white; border: none; padding: 12px 20px; border-radius: 8px; font-size: 14px; font-weight: bold; width: 100%; margin: 10px 0; opacity: 0.7; cursor: not-allowed;" disabled>ğŸ“„ {news_title} (æ— æœ‰æ•ˆé“¾æ¥)</button>', unsafe_allow_html=True)
                
                # å¸‚åœºå½±å“åˆ†æ
                col_sentiment, col_impact = st.columns([1, 2])
                
                with col_sentiment:
                    sentiment = news.get('sentiment', 'ä¸­æ€§')
                    if sentiment == "åˆ©å¥½":
                        st.success(f"ğŸ“ˆ **{sentiment}**")
                    elif sentiment == "åˆ©ç©º":
                        st.error(f"ğŸ“‰ **{sentiment}**")
                    else:
                        st.info(f"ğŸ“Š **{sentiment}**")
                
                with col_impact:
                    impact_info = get_market_impact_advice(sentiment)
                    st.write(f"{impact_info['icon']} {impact_info['advice']}")
                    st.caption(f"ğŸ’¡ æ“ä½œå»ºè®®: {impact_info['action']}")
                
                st.markdown("---")
            
            # é¡µé¢åº•éƒ¨çš„ç¿»é¡µæŒ‰é’®
            if total_pages > 1:
                st.markdown("### ğŸ“„ é¡µé¢å¯¼èˆª")
                
                # åˆ›å»ºç¿»é¡µæŒ‰é’®å¸ƒå±€
                nav_col1, nav_col2, nav_col3, nav_col4, nav_col5 = st.columns([1, 1, 1, 1, 1])
                
                with nav_col1:
                    if current_page > 1:
                        if st.button("â¬…ï¸ ä¸Šä¸€é¡µ", key="prev_page_btn", use_container_width=True):
                            st.session_state.current_news_page = current_page - 1
                            st.rerun()
                    else:
                        st.button("â¬…ï¸ ä¸Šä¸€é¡µ", key="prev_page_btn_disabled", disabled=True, use_container_width=True)
                
                with nav_col2:
                    if st.button("ğŸ“– ç¬¬1é¡µ", key="page_1_btn", use_container_width=True, 
                               type="primary" if current_page == 1 else "secondary"):
                        st.session_state.current_news_page = 1
                        st.rerun()
                
                with nav_col3:
                    st.markdown(f"<div style='text-align: center; padding: 10px; font-weight: bold; color: #666;'>ç¬¬ {current_page} / {total_pages} é¡µ</div>", unsafe_allow_html=True)
                
                with nav_col4:
                    if total_pages >= 2:
                        if st.button("ğŸ“„ ç¬¬2é¡µ", key="page_2_btn", use_container_width=True,
                                   type="primary" if current_page == 2 else "secondary"):
                            st.session_state.current_news_page = 2
                            st.rerun()
                    else:
                        st.button("ğŸ“„ ç¬¬2é¡µ", key="page_2_btn_disabled", disabled=True, use_container_width=True)
                
                with nav_col5:
                    if current_page < total_pages:
                        if st.button("ä¸‹ä¸€é¡µ â¡ï¸", key="next_page_btn", use_container_width=True):
                            st.session_state.current_news_page = current_page + 1
                            st.rerun()
                    else:
                        st.button("ä¸‹ä¸€é¡µ â¡ï¸", key="next_page_btn_disabled", disabled=True, use_container_width=True)
                
                # é¡µé¢çŠ¶æ€æŒ‡ç¤ºå™¨
                st.markdown("---")
                progress_text = f"ğŸ”– å½“å‰æµè§ˆ: ç¬¬{current_page}é¡µï¼Œå…±{total_pages}é¡µ | æ˜¾ç¤ºæ–°é—» {start_idx + 1}-{end_idx} / {len(news_data)}"
                st.info(progress_text)
            
            # æ•´ä½“å¸‚åœºæƒ…ç»ªåˆ†æ
            st.subheader("ğŸ“Š æ•´ä½“å¸‚åœºæƒ…ç»ªåˆ†æ")
            
            bullish_count = sum(1 for news in news_data if news.get('sentiment') == 'åˆ©å¥½')
            bearish_count = sum(1 for news in news_data if news.get('sentiment') == 'åˆ©ç©º')
            neutral_count = sum(1 for news in news_data if news.get('sentiment') == 'ä¸­æ€§')
            
            col_stats1, col_stats2, col_stats3 = st.columns(3)
            with col_stats1:
                st.metric("ğŸ“ˆ åˆ©å¥½æ¶ˆæ¯", bullish_count)
            with col_stats2:
                st.metric("ğŸ“‰ åˆ©ç©ºæ¶ˆæ¯", bearish_count)
            with col_stats3:
                st.metric("ğŸ“Š ä¸­æ€§æ¶ˆæ¯", neutral_count)
            
            # æ•´ä½“å»ºè®®
            if bullish_count > bearish_count:
                st.success("ğŸŸ¢ **æ•´ä½“å¸‚åœºæƒ…ç»ª**: åå‘ä¹è§‚")
                st.info("ğŸ’¡ **æŠ•èµ„å»ºè®®**: å¸‚åœºåˆ©å¥½å› ç´ è¾ƒå¤šï¼Œå¯é€‚å½“å…³æ³¨ä¼˜è´¨æ ‡çš„æŠ•èµ„æœºä¼šã€‚")
            elif bearish_count > bullish_count:
                st.error("ğŸ”´ **æ•´ä½“å¸‚åœºæƒ…ç»ª**: åå‘è°¨æ…")
                st.warning("âš ï¸ **æŠ•èµ„å»ºè®®**: å¸‚åœºé£é™©å› ç´ å¢åŠ ï¼Œå»ºè®®é™ä½ä»“ä½ï¼Œå…³æ³¨é˜²å¾¡æ€§èµ„äº§ã€‚")
            else:
                st.info("ğŸŸ¡ **æ•´ä½“å¸‚åœºæƒ…ç»ª**: ç›¸å¯¹å¹³è¡¡")
                st.info("ğŸ“Š **æŠ•èµ„å»ºè®®**: å¸‚åœºæƒ…ç»ªç›¸å¯¹å¹³è¡¡ï¼Œå»ºè®®ä¿æŒç°æœ‰æŠ•èµ„ç­–ç•¥ã€‚")
            
            # å…³é”®è¯åˆ†æ
            st.subheader("ğŸ” çƒ­ç‚¹å…³é”®è¯")
            all_keywords = []
            for news in news_data:
                all_keywords.extend(news.get('keywords', []))
            
            keyword_count = {}
            for keyword in all_keywords:
                keyword_count[keyword] = keyword_count.get(keyword, 0) + 1
            
            sorted_keywords = sorted(keyword_count.items(), key=lambda x: x[1], reverse=True)[:8]
            
            cols = st.columns(4)
            for i, (keyword, count) in enumerate(sorted_keywords):
                with cols[i % 4]:
                    st.metric(f"ğŸ·ï¸ {keyword}", f"{count}æ¬¡")
            
            # æŠ•èµ„å»ºè®®
            st.subheader("ğŸ’¡ åŸºäºçœŸå®æ—¶äº‹çš„æŠ•èµ„æé†’")
            
            suggestions = []
            for keyword, count in sorted_keywords:
                if keyword in ["åˆ©ç‡", "é™æ¯"]:
                    suggestions.append("ğŸŸ¢ å…³æ³¨åˆ©ç‡æ•æ„Ÿè¡Œä¸šï¼šæˆ¿åœ°äº§ã€é“¶è¡Œã€åŸºå»ºç­‰")
                elif keyword in ["ç§‘æŠ€", "AI"]:
                    suggestions.append("ğŸ”µ å…³æ³¨ç§‘æŠ€æˆé•¿è‚¡ï¼šäººå·¥æ™ºèƒ½ã€èŠ¯ç‰‡ã€è½¯ä»¶ç­‰")
                elif keyword in ["æ–°èƒ½æº"]:
                    suggestions.append("âš¡ å…³æ³¨æ–°èƒ½æºäº§ä¸šé“¾ï¼šç”µåŠ¨è½¦ã€å…‰ä¼ã€ç”µæ± ç­‰")
            
            unique_suggestions = list(set(suggestions))
            for suggestion in unique_suggestions[:5]:
                st.write(suggestion)
            
            st.markdown("---")
            st.caption("ğŸ“ **æ•°æ®æ¥æº**: åŸºäºYahoo Financeç­‰çœŸå®è´¢ç»æ•°æ®æº")
            st.caption("âœ… **çœŸå®æ€§ä¿è¯**: æ‰€æœ‰æ–°é—»å‡ä¸ºçœŸå®è·å–ï¼Œæ— ä»»ä½•æ¨¡æ‹Ÿå†…å®¹")
            st.caption("âš ï¸ **å…è´£å£°æ˜**: æ‰€æœ‰åˆ†æä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚æŠ•èµ„æœ‰é£é™©ï¼Œå…¥å¸‚éœ€è°¨æ…ã€‚")

else:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾“å…¥è‚¡ç¥¨ä»£ç å¹¶ç‚¹å‡»åˆ†ææŒ‰é’®å¼€å§‹")
    
    with st.expander("ğŸ“– ç³»ç»ŸåŠŸèƒ½ä»‹ç»"):
        st.markdown("""
        ### ğŸ¯ ä¸»è¦åŠŸèƒ½
        
        **ğŸ“Š è‚¡ç¥¨åˆ†æ**
        - å…¬å¸åŸºæœ¬ä¿¡æ¯å±•ç¤º
        - Piotroski F-Scoreè´¢åŠ¡å¥åº·è¯„åˆ†
        - DCFä¼°å€¼æ¨¡å‹è®¡ç®—å®‰å…¨è¾¹é™…
        - æŠ€æœ¯æŒ‡æ ‡åˆ†æï¼ˆRSIã€å‡çº¿ç­‰ï¼‰
        - æ™ºèƒ½æ­¢ç›ˆæ­¢æŸå»ºè®®
        
        **ğŸ“° çœŸå®æ–°é—»åˆ†æ**
        - è·å–çœŸå®è´¢ç»æ–°é—»ï¼ˆå…¬å¸+è¡Œä¸š+å¸‚åœºï¼‰
        - æ™ºèƒ½åˆ†é¡µæµè§ˆï¼ˆæ¯é¡µ5æ¡ï¼‰
        - è‡ªåŠ¨æƒ…ç»ªåˆ†æï¼ˆåˆ©å¥½/åˆ©ç©º/ä¸­æ€§ï¼‰
        - å¸‚åœºå½±å“è¯„ä¼°å’Œæ“ä½œå»ºè®®
        - çƒ­ç‚¹å…³é”®è¯ç»Ÿè®¡
        - æ•´ä½“å¸‚åœºæƒ…ç»ªåˆ†æ
        - **100%çœŸå®æ–°é—»ï¼Œç»æ— æ¨¡æ‹Ÿå†…å®¹**
        
        ### ğŸš€ ä½¿ç”¨æ–¹æ³•
        1. åœ¨ä¾§è¾¹æ è¾“å…¥è‚¡ç¥¨ä»£ç ï¼ˆå¦‚AAPLã€TSLAã€MSFTç­‰ï¼‰
        2. ç‚¹å‡»"ğŸ” å¼€å§‹åˆ†æ"æŒ‰é’®
        3. æŸ¥çœ‹"ğŸ“Š è‚¡ç¥¨åˆ†æ"æ ‡ç­¾é¡µçš„è´¢åŠ¡å’ŒæŠ€æœ¯åˆ†æ
        4. åˆ‡æ¢åˆ°"ğŸ“° çœŸå®æ–°é—»åˆ†æ"æŸ¥çœ‹ç›¸å…³æ–°é—»
        5. ä½¿ç”¨åˆ†é¡µåŠŸèƒ½æµè§ˆæ‰€æœ‰æ–°é—»å†…å®¹
        
        ### ğŸ“‹ æ³¨æ„äº‹é¡¹
        - æœ¬ç³»ç»Ÿä»…æ˜¾ç¤ºçœŸå®è´¢ç»æ–°é—»
        - æ–°é—»æ•°é‡å–å†³äºå®é™…å¯è·å–çš„æ•°æ®
        - æœ¬ç³»ç»Ÿä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®
        - è¯·ç»“åˆå…¶ä»–ä¿¡æ¯è¿›è¡Œç»¼åˆåˆ¤æ–­
        - æŠ•èµ„æœ‰é£é™©ï¼Œå…¥å¸‚éœ€è°¨æ…
        """)

# é¡µè„š
st.markdown("---")
col_footer1, col_footer2, col_footer3 = st.columns([1, 2, 1])
with col_footer2:
    if st.button("ğŸ”™ è¿”å›é¦–é¡µ / æ¸…é™¤æ•°æ®", type="secondary", use_container_width=True):
        st.session_state.show_analysis = False
        st.session_state.current_ticker = None
        st.session_state.current_price = 0
        st.session_state.analysis_data = None
        st.rerun()

st.markdown("ğŸ’¹ æ™ºèƒ½æŠ•èµ„åˆ†æç³»ç»Ÿ v2.0 | ä»…çœŸå®æ–°é—» | æŠ•èµ„éœ€è°¨æ…")
